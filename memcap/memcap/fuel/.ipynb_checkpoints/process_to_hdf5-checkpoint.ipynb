{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lets download the annotations from http://mscoco.org/dataset/#download\n",
    "import os\n",
    "import json\n",
    "coco = json.load(open('../../Data/neural_talk_data/caption_datasets/dataset_coco.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H7_18_2\n",
      "8\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "name = \"H7_18_2_augment_42\"\n",
    "idx = name.find('augment')\n",
    "ident = name[0:idx-1]\n",
    "print(ident)\n",
    "print(name.find('augment'))\n",
    "\n",
    "naked = \"H7_18_2\"\n",
    "print(naked.find('augment'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from copy import copy\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "    \n",
    "def cumprod(inputs, dim = 1, exclusive=True):\n",
    "    # https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/api_docs/python/functions_and_classes/shard0/tf.cumprod.md\n",
    "\n",
    "    if type(inputs) is not Variable:\n",
    "        temp = torch.cumprod(inputs, dim)\n",
    "        if not exclusive:\n",
    "            return temp\n",
    "        else:\n",
    "            temp =  temp / (inputs[0].expand_as(temp) + 1e-8)\n",
    "            temp[-1] = temp[-1]/(inputs[-1]+1e-8)\n",
    "            return temp\n",
    "    else:\n",
    "        shape_ = inputs.size()\n",
    "        ndim = len(shape_)\n",
    "        n_slot = shape_[dim]\n",
    "        output = Variable(inputs.data.new(*shape_).fill_(1.0), requires_grad = True)\n",
    "        slice_ = [slice(0,None,1) for _ in range(ndim)]\n",
    "        results = [[]] * n_slot\n",
    "            \n",
    "        for ind in range(0, n_slot):   \n",
    "            this_slice, last_slice = copy(slice_), copy(slice_)\n",
    "            this_slice[dim] = ind\n",
    "            last_slice[dim] = ind-1      \n",
    "            this_slice = tuple(this_slice)\n",
    "            last_slice = tuple(last_slice)\n",
    "            if exclusive: \n",
    "                if ind > 0:   \n",
    "                    results[ind]  = results[ind-1]*inputs[last_slice]\n",
    "                else:\n",
    "                    results[ind] =  torch.div(inputs[this_slice], inputs[this_slice]+1e-8)\n",
    "            else:    \n",
    "                if ind > 0:   \n",
    "                    results[ind]  = results[ind - 1]*inputs[this_slice]\n",
    "                else:\n",
    "                    results[ind] =  inputs[this_slice]\n",
    "        \n",
    "        return torch.stack(results, dim)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(0 ,.,.) = \n",
      "\n",
      "Columns 0 to 5 \n",
      "   1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00\n",
      "  1.2380e-02  8.2014e-01  3.1398e-01  3.3402e-01  4.9230e-01  5.9409e-01\n",
      "  1.7017e-03  1.3565e-01  2.3858e-01  6.5125e-02  1.1800e-01  3.7724e-01\n",
      "  1.0334e-03  1.0960e-01  2.0630e-01  1.4763e-02  7.0547e-02  1.4239e-01\n",
      "  3.9495e-04  2.8719e-02  1.8118e-01  1.1700e-02  1.6119e-02  5.1091e-03\n",
      "  2.8580e-04  1.6485e-02  5.4713e-03  8.6700e-03  1.1686e-03  3.2970e-03\n",
      "  9.4465e-05  1.3901e-02  3.2437e-03  1.6170e-03  2.2537e-04  1.5956e-04\n",
      "\n",
      "Columns 6 to 9 \n",
      "   1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00\n",
      "  1.4994e-01  1.5362e-01  7.4491e-01  9.0026e-01\n",
      "  3.9125e-02  9.5919e-02  4.2028e-01  3.9816e-01\n",
      "  3.0712e-02  7.4007e-02  1.9172e-01  8.0500e-02\n",
      "  2.8970e-02  2.9490e-02  1.6206e-01  9.5200e-03\n",
      "  2.1421e-02  2.5570e-02  1.0066e-01  3.3785e-03\n",
      "  1.5951e-02  1.9465e-02  2.0693e-02  6.2897e-04\n",
      "\n",
      "(1 ,.,.) = \n",
      "\n",
      "Columns 0 to 5 \n",
      "   6.7478e+01  2.2732e-01  4.1368e-01  2.4346e+00  1.9932e+00  1.1120e+00\n",
      "  4.7911e+00  9.4671e-01  5.6449e-02  1.4882e+00  2.4703e-01  8.6467e-01\n",
      "  5.5682e-02  1.4064e-01  4.9031e-02  8.1211e-02  3.6870e-02  3.8730e-01\n",
      "  7.2355e-03  1.7924e-01  5.2448e-03  1.8135e-02  6.5188e-03  2.0747e+00\n",
      "  3.0495e-03  6.6874e-02  7.3507e-02  8.5689e-03  1.6364e-02  4.6071e-02\n",
      "  3.8457e-03  3.8079e-03  2.2842e-03  1.8378e-02  8.7986e-04  4.6807e-02\n",
      "  1.2951e-04  2.5626e-03  1.6941e-03  2.4313e-03  4.5540e-05  2.5981e-02\n",
      "\n",
      "Columns 6 to 9 \n",
      "   3.8553e+00  6.3517e-01  5.7258e-01  1.0334e+00\n",
      "  2.0473e-01  8.6685e-02  8.8969e-02  6.8300e-01\n",
      "  2.8524e-02  2.6179e-02  1.0992e-01  1.1595e-01\n",
      "  6.9409e-03  2.5970e-02  5.0091e-02  2.5265e-02\n",
      "  2.9667e-03  8.2982e-03  6.6085e-02  2.6695e-04\n",
      "  1.5743e-03  6.7421e-03  8.3135e-02  4.1681e-04\n",
      "  1.7189e-03  3.8831e-03  4.1617e-02  2.5524e-04\n",
      "\n",
      "(2 ,.,.) = \n",
      "\n",
      "Columns 0 to 5 \n",
      "   3.8007e+01  2.9068e-01  6.0679e-01  2.2100e+00  1.1460e+00  1.1894e-01\n",
      "  7.2939e-01  4.4035e-01  1.5734e-01  1.8380e+00  3.5983e-02  9.9716e-02\n",
      "  1.6328e-01  6.9818e-03  6.8164e-02  5.4042e-01  1.2106e-02  1.5518e-01\n",
      "  9.3622e-02  1.1769e-02  3.1229e-02  8.8958e-02  2.4573e-02  8.9439e-01\n",
      "  2.7549e-02  4.2624e-03  6.9521e-01  6.4139e-02  2.2472e-02  3.6779e-02\n",
      "  1.0722e-02  2.0373e-03  3.1017e-02  1.0939e-01  3.5242e-03  9.4049e-02\n",
      "  5.2504e-03  5.0380e-04  2.9278e-02  2.2829e-02  1.0748e-03  4.9195e-02\n",
      "\n",
      "Columns 6 to 9 \n",
      "   5.8027e+00  6.0002e+00  7.5135e-01  6.9365e-01\n",
      "  2.4220e+00  9.8596e-01  7.5014e-01  4.3320e-01\n",
      "  2.5305e-01  2.2050e-01  5.8904e-01  3.1305e-01\n",
      "  9.8512e-03  2.0442e-01  2.1202e-01  2.6900e-01\n",
      "  1.0401e-02  5.9178e-02  3.4915e-02  6.0553e-04\n",
      "  5.3054e-03  4.5727e-02  3.8381e-02  5.8518e-04\n",
      "  7.4596e-03  3.7960e-03  1.3563e-02  2.2902e-04\n",
      "\n",
      "(3 ,.,.) = \n",
      "\n",
      "Columns 0 to 5 \n",
      "   8.0776e+01  1.2193e+00  3.1849e+00  2.9938e+00  2.0313e+00  1.6833e+00\n",
      "  4.0460e+00  2.3438e+00  7.9694e-01  2.9009e+00  1.2035e+00  3.8483e-01\n",
      "  3.1133e-01  4.3159e-02  6.6402e-01  2.8311e-01  7.6374e-03  2.1042e-01\n",
      "  1.0741e-01  6.4171e-02  6.3032e-01  2.8153e-02  8.5392e-03  1.3470e+00\n",
      "  4.8574e-02  1.7789e-03  1.7068e+01  1.6855e-02  1.7163e-02  2.3785e-02\n",
      "  1.0506e-01  6.8544e-04  6.5058e-02  5.1842e-02  3.5715e-03  2.6058e-01\n",
      "  2.6416e-01  4.8520e-04  5.0633e-02  1.0023e-02  2.9450e-04  1.0704e-01\n",
      "\n",
      "Columns 6 to 9 \n",
      "   6.6692e+00  6.5096e+00  1.3424e+00  1.1108e+00\n",
      "  2.3511e+00  5.9082e-01  1.4517e+00  1.8842e+00\n",
      "  5.0789e-01  8.6113e-02  7.7773e-01  3.3072e+00\n",
      "  1.7611e-01  1.4359e-01  2.4995e-01  1.6241e+00\n",
      "  8.2644e-02  6.4733e-02  2.4294e-01  7.3323e-02\n",
      "  2.6758e-02  5.8179e-02  3.3183e-01  4.0803e-02\n",
      "  1.7993e-03  2.2195e-02  1.1566e-01  1.4364e-02\n",
      "[torch.FloatTensor of size 4x7x10]\n",
      " Variable containing:\n",
      "(0 ,.,.) = \n",
      "\n",
      "Columns 0 to 5 \n",
      "   1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00\n",
      "  1.2380e-02  8.2014e-01  3.1398e-01  3.3402e-01  4.9230e-01  5.9409e-01\n",
      "  1.7017e-03  1.3565e-01  2.3858e-01  6.5125e-02  1.1800e-01  3.7724e-01\n",
      "  1.0334e-03  1.0960e-01  2.0630e-01  1.4763e-02  7.0547e-02  1.4239e-01\n",
      "  3.9495e-04  2.8719e-02  1.8119e-01  1.1700e-02  1.6119e-02  5.1091e-03\n",
      "  2.8580e-04  1.6485e-02  5.4713e-03  8.6700e-03  1.1686e-03  3.2970e-03\n",
      "  9.4465e-05  1.3901e-02  3.2437e-03  1.6170e-03  2.2537e-04  1.5956e-04\n",
      "\n",
      "Columns 6 to 9 \n",
      "   1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00\n",
      "  1.4994e-01  1.5362e-01  7.4491e-01  9.0026e-01\n",
      "  3.9125e-02  9.5919e-02  4.2028e-01  3.9816e-01\n",
      "  3.0712e-02  7.4007e-02  1.9172e-01  8.0500e-02\n",
      "  2.8970e-02  2.9490e-02  1.6206e-01  9.5200e-03\n",
      "  2.1421e-02  2.5570e-02  1.0066e-01  3.3785e-03\n",
      "  1.5951e-02  1.9465e-02  2.0693e-02  6.2897e-04\n",
      "\n",
      "(1 ,.,.) = \n",
      "\n",
      "Columns 0 to 5 \n",
      "   1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00\n",
      "  8.3537e-01  1.8643e-01  1.2989e-01  8.1320e-01  9.8126e-01  6.6063e-01\n",
      "  6.5856e-01  1.5658e-01  4.2892e-02  2.9016e-01  5.9210e-02  5.4906e-01\n",
      "  3.3815e-02  1.1363e-01  4.2398e-02  1.8409e-02  2.2043e-02  1.4618e-01\n",
      "  2.7652e-03  4.6968e-02  4.6063e-03  1.4373e-02  1.4895e-03  7.4443e-02\n",
      "  2.2067e-03  3.8387e-02  2.2197e-03  6.3495e-03  1.1863e-03  2.9731e-02\n",
      "  1.2711e-03  3.2111e-03  1.3542e-03  3.4276e-03  1.6968e-04  2.2652e-03\n",
      "\n",
      "Columns 6 to 9 \n",
      "   1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00\n",
      "  5.7807e-01  9.7575e-02  4.2652e-01  9.3031e-01\n",
      "  5.3421e-02  5.4125e-02  5.0195e-02  3.0207e-01\n",
      "  2.2390e-02  2.0199e-02  5.0143e-02  2.3442e-02\n",
      "  6.5472e-03  1.0348e-02  4.2341e-02  2.9878e-03\n",
      "  2.1936e-03  7.1951e-03  4.1046e-02  9.4738e-05\n",
      "  1.1723e-03  5.1325e-03  1.7091e-02  7.7596e-05\n",
      "\n",
      "(2 ,.,.) = \n",
      "\n",
      "Columns 0 to 5 \n",
      "   1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00\n",
      "  4.7052e-01  2.3840e-01  1.9052e-01  7.3819e-01  5.6420e-01  7.0659e-02\n",
      "  1.0026e-01  7.2831e-02  1.1955e-01  3.5836e-01  8.6249e-03  6.3319e-02\n",
      "  9.9159e-02  5.6411e-03  5.8943e-02  1.2250e-01  7.2375e-03  5.8570e-02\n",
      "  3.5780e-02  3.0839e-03  2.7427e-02  7.0504e-02  5.6146e-03  3.2092e-02\n",
      "  1.9935e-02  2.4467e-03  2.0993e-02  4.7527e-02  1.6292e-03  2.3734e-02\n",
      "  3.5441e-03  1.7180e-03  1.8389e-02  2.0403e-02  6.7965e-04  4.5515e-03\n",
      "\n",
      "Columns 6 to 9 \n",
      "   1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00\n",
      "  8.7006e-01  9.2175e-01  5.5969e-01  6.2447e-01\n",
      "  6.3198e-01  6.1562e-01  4.2323e-01  1.9159e-01\n",
      "  1.9863e-01  1.7013e-01  2.6870e-01  6.3293e-02\n",
      "  9.2925e-03  8.1455e-02  1.7922e-01  3.1812e-02\n",
      "  7.6909e-03  5.1311e-02  2.1686e-02  2.1490e-04\n",
      "  3.9507e-03  3.4810e-02  7.8905e-03  1.0894e-04\n",
      "\n",
      "(3 ,.,.) = \n",
      "\n",
      "Columns 0 to 5 \n",
      "   1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00\n",
      "  5.5614e-01  3.8765e-01  6.0555e-01  5.6559e-01  2.8846e-01  2.4436e-01\n",
      "  1.8907e-01  3.4871e-02  5.7419e-01  6.4177e-02  4.5661e-03  7.9420e-02\n",
      "  4.1050e-02  1.6815e-02  5.5358e-01  2.2313e-02  1.9511e-03  4.8334e-02\n",
      "  3.5150e-02  1.0211e-03  5.1541e-01  1.2490e-02  1.2443e-03  1.5349e-02\n",
      "  3.4727e-02  5.7801e-04  3.8569e-02  9.6690e-03  6.8878e-04  1.2611e-02\n",
      "  3.2294e-02  4.8019e-04  1.8200e-02  8.2606e-03  1.8416e-04  8.6674e-03\n",
      "\n",
      "Columns 6 to 9 \n",
      "   1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00\n",
      "  6.1348e-01  3.6890e-01  8.1905e-01  8.3332e-01\n",
      "  3.9867e-01  6.6442e-02  3.5478e-01  6.6864e-01\n",
      "  1.6612e-01  5.7215e-02  2.1128e-01  1.9207e-01\n",
      "  6.1108e-02  5.6128e-02  1.5089e-01  2.6021e-02\n",
      "  1.9926e-02  4.4289e-02  6.8219e-02  7.5961e-03\n",
      "  9.4465e-04  2.1253e-02  4.3544e-02  3.9331e-03\n",
      "[torch.FloatTensor of size 4x7x10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "data = torch.rand(4,7,10)\n",
    "\n",
    "data_var = Variable(data)\n",
    "\n",
    "result = cumprod(data, 1, True)\n",
    "result_var = cumprod(data_var)\n",
    "\n",
    "print(result, result_var)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "W = nn.Parameter(torch.Tensor(4,7,10))\n",
    "\n",
    "data_pre = data_var * W\n",
    "#print(data)\n",
    "#result = cumprod(data, 1, True)\n",
    "result_var = cumprod(data_pre)\n",
    "\n",
    "#print(result_var)\n",
    "\n",
    "loss = torch.sum(result_var) *0.5\n",
    "loss.backward()\n",
    "\n",
    "print(W.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(0 ,.,.) = \n",
      "  0.7615  0.5426\n",
      "  0.0270  0.2162\n",
      "  0.4347  0.5452\n",
      "\n",
      "(1 ,.,.) = \n",
      "  0.4225  0.8997\n",
      "  0.9161  0.7573\n",
      "  0.6608  0.1834\n",
      "\n",
      "(2 ,.,.) = \n",
      "  0.6764  0.6198\n",
      "  0.0159  0.6918\n",
      "  0.7290  0.8699\n",
      "\n",
      "(3 ,.,.) = \n",
      "  0.7890  0.4502\n",
      "  0.1355  0.5624\n",
      "  0.8061  0.9127\n",
      "[torch.FloatTensor of size 4x3x2]\n",
      "\n",
      "\n",
      " 0.7615  0.5426\n",
      " 0.0270  0.2162\n",
      " 0.4347  0.5452\n",
      " 0.4225  0.8997\n",
      " 0.9161  0.7573\n",
      " 0.6608  0.1834\n",
      " 0.6764  0.6198\n",
      " 0.0159  0.6918\n",
      " 0.7290  0.8699\n",
      " 0.7890  0.4502\n",
      " 0.1355  0.5624\n",
      " 0.8061  0.9127\n",
      "[torch.FloatTensor of size 12x2]\n",
      "\n",
      "\n",
      " 0.0270\n",
      " 0.2162\n",
      "[torch.FloatTensor of size 2]\n",
      "\n",
      "=================\n",
      "\n",
      " 0.0270  0.2162\n",
      " 0.6764  0.6198\n",
      " 0.6608  0.1834\n",
      "[torch.FloatTensor of size 3x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dat = torch.rand(4,3,2)\n",
    "row, col, dim = dat.size()\n",
    "\n",
    "print(dat)\n",
    "flat_dat = dat.view(-1,2)\n",
    "print(flat_dat)\n",
    "first = torch.LongTensor([0,2,1])\n",
    "second = torch.LongTensor([1,0,2])\n",
    "\n",
    "print(dat[0,1])\n",
    "index = first*col + second\n",
    "select = flat_dat[index]\n",
    "\n",
    "print('=================')\n",
    "print(select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 4, 20])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pad_packed_sequence as unpack\n",
    "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
    "\n",
    "def sort_batch(data, seq_len):\n",
    "    batch_size = data.size(0)\n",
    "    sorted_seq_len, sorted_idx  = torch.sort(seq_len, dim=0, descending=True)\n",
    "    sorted_data = data[sorted_idx]\n",
    "    _, reverse_idx  = torch.sort(sorted_idx, dim=0, descending=False)\n",
    "    return sorted_data, sorted_seq_len, reverse_idx\n",
    "\n",
    "data = torch.rand(4,7,10)\n",
    "lens = torch.LongTensor([3,7,2,1])\n",
    "\n",
    "s_data, s_len, reverse_idx = sort_batch(data, lens)\n",
    "\n",
    "emb = pack(Variable(s_data), list(s_len),batch_first=True)\n",
    "\n",
    "rnn = nn.LSTM(10, 20, 2, batch_first =True, bidirectional=False)\n",
    "input = emb\n",
    "h0 = Variable(torch.randn(2, 6, 20))\n",
    "c0 = Variable(torch.randn(2, 6, 20))\n",
    "packed_output, hn = rnn(input)\n",
    "result, lens = unpack(packed_output)\n",
    "print(result.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 7, 20])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pad_packed_sequence as unpack\n",
    "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
    "\n",
    "data = Variable(torch.rand(4,7,10))\n",
    "lens = torch.LongTensor([3,7,2,1])\n",
    "\n",
    "#s_data, s_len, reverse_idx = sort_batch(data, lens)\n",
    "\n",
    "rnn = nn.LSTM(10, 20, 2, batch_first =True, bidirectional=False)\n",
    "\n",
    "h0 = Variable(torch.randn(2, 6, 20))\n",
    "c0 = Variable(torch.randn(2, 6, 20))\n",
    "output, hn = rnn(data)\n",
    "\n",
    "#result, lens = unpack(packed_output)\n",
    "print(output.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "a = Variable(torch.Tensor([1]))\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "print(cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\n",
      " 6\n",
      " 2\n",
      " 1\n",
      " 0\n",
      "[torch.LongTensor of size 4]\n",
      ", \n",
      " 0\n",
      " 1\n",
      " 2\n",
      " 3\n",
      "[torch.LongTensor of size 4]\n",
      ")\n",
      "('result', torch.Size([7, 4, 20]))\n",
      "('last out', torch.Size([4, 20]))\n",
      "Variable containing:\n",
      "-0.0213  0.0501 -0.1353 -0.0388 -0.0474 -0.2192  0.0512 -0.1225\n",
      "-0.0184  0.0430 -0.1112 -0.0204 -0.0506 -0.1931  0.0632 -0.0996\n",
      "-0.0140  0.0469 -0.0929 -0.0135 -0.0487 -0.1604  0.0630 -0.0850\n",
      "-0.0202  0.0292 -0.0607  0.0021 -0.0313 -0.1138  0.0473 -0.0582\n",
      "[torch.FloatTensor of size 4x8]\n",
      "\n",
      "---------------\n",
      "Variable containing:\n",
      "(0 ,.,.) = \n",
      " -0.0203  0.0331 -0.0582  0.0013 -0.0381 -0.1165  0.0493 -0.0546\n",
      " -0.0086  0.0298 -0.0589 -0.0036 -0.0282 -0.1145  0.0368 -0.0562\n",
      " -0.0119  0.0327 -0.0614 -0.0033 -0.0302 -0.1074  0.0475 -0.0600\n",
      " -0.0202  0.0292 -0.0607  0.0021 -0.0313 -0.1138  0.0473 -0.0582\n",
      "\n",
      "(1 ,.,.) = \n",
      " -0.0281  0.0402 -0.0977 -0.0021 -0.0458 -0.1637  0.0722 -0.0916\n",
      " -0.0160  0.0365 -0.0948 -0.0093 -0.0365 -0.1666  0.0549 -0.0874\n",
      " -0.0140  0.0469 -0.0929 -0.0135 -0.0487 -0.1604  0.0630 -0.0850\n",
      "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "\n",
      "(2 ,.,.) = \n",
      " -0.0267  0.0469 -0.1205 -0.0196 -0.0441 -0.1895  0.0718 -0.1090\n",
      " -0.0184  0.0430 -0.1112 -0.0204 -0.0506 -0.1931  0.0632 -0.0996\n",
      "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "\n",
      "(3 ,.,.) = \n",
      " -0.0339  0.0497 -0.1261 -0.0254 -0.0534 -0.2031  0.0729 -0.1181\n",
      "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "\n",
      "(4 ,.,.) = \n",
      " -0.0332  0.0486 -0.1330 -0.0302 -0.0456 -0.2139  0.0659 -0.1257\n",
      "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "\n",
      "(5 ,.,.) = \n",
      " -0.0289  0.0496 -0.1346 -0.0340 -0.0479 -0.2163  0.0599 -0.1282\n",
      "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "\n",
      "(6 ,.,.) = \n",
      " -0.0213  0.0501 -0.1353 -0.0388 -0.0474 -0.2192  0.0512 -0.1225\n",
      "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "[torch.FloatTensor of size 7x4x8]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def two_ind(data, first, second):\n",
    "    '''\n",
    "    data: 3 dimension\n",
    "    first: 1 d tensor\n",
    "    second: 1 d tensor\n",
    "    '''\n",
    "    row, col, dim = data.size()\n",
    "    index = first*col + second\n",
    "    last_out = result.view(-1, dim)[index]\n",
    "    return last_out\n",
    "    \n",
    "lens_th = Variable(torch.LongTensor(lens))    \n",
    "first  = (lens_th -1).data \n",
    "second = torch.range(0, len(lens)-1).long()\n",
    "\n",
    "print(first, second)\n",
    "last_out = two_ind(result, first, second)\n",
    "#last_out = torch.index_select(torch.index_select(second, 0, lens_th-1), 1, second)\n",
    "#last_out = result[lens_th.data-1, :][:,second]\n",
    "                   \n",
    "print('result', result.size())\n",
    "print('last out',last_out.size())\n",
    "\n",
    "print(last_out[:,0:8])\n",
    "print('---------------')\n",
    "print(result[:, :, 0:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\n",
      "-1.5788  1.3199  1.7161  0.5836\n",
      " 0.9811  2.5551 -0.3949  0.9135\n",
      " 0.0840 -0.0228  1.3977 -1.0893\n",
      " 0.4723 -0.3251 -0.4061  1.2842\n",
      "-1.5411 -1.1587  0.8768  0.8281\n",
      "[torch.FloatTensor of size 5x4]\n",
      ", \n",
      "-1.0217  0.7216  0.3534 -0.9644\n",
      "-0.1993 -0.1303  0.6186  0.4552\n",
      " 0.2413  0.9452 -1.2923 -0.1830\n",
      " 0.4121  1.4143  0.4108  0.6924\n",
      " 0.6960  1.5349  1.8151  0.0185\n",
      "[torch.FloatTensor of size 5x4]\n",
      ")\n",
      "\n",
      " 0.5879\n",
      "-0.1524\n",
      "-0.5563\n",
      " 0.1860\n",
      "-0.2209\n",
      "[torch.FloatTensor of size 5x1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch1 = torch.randn(5, 4)\n",
    "batch2 = torch.randn(5, 4)\n",
    "\n",
    "print(batch1,batch2)\n",
    "\n",
    "def cosine_similarity(first, second):\n",
    "    \"\"\"\n",
    "    compute the cosine similarity between keys to each of the \n",
    "    memory slot.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    first: Tensor (batch_size, dim)\n",
    "        the memory matrix to lookup in\n",
    "    second: Tensor (batch_size, dim)\n",
    "        the keys to query the memory with\n",
    "    Returns: Tensor (batch_size, 1)\n",
    "    \"\"\"\n",
    "    first_norm  = torch.norm(first,  2, 1)\n",
    "    second_norm = torch.norm(second, 2, 1)\n",
    "\n",
    "    normalized_first  = torch.div(first,  first_norm.expand_as(first) + 1e-10)\n",
    "    normalized_second = torch.div(second, second_norm.expand_as(second) + 1e-10)\n",
    "\n",
    "    return torch.sum(normalized_first*normalized_second,1)\n",
    "\n",
    "cos = cosine_similarity(batch1, batch2)\n",
    "print(cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.48210773  0.752584    0.64944821  0.19314062  0.03171795  0.26378825]\n",
      " [ 0.14147113  0.4699371   0.66200108  0.78925308  0.94670398  0.18808383]\n",
      " [ 0.59918571  0.57468536  0.66673667  0.98518522  0.20246986  0.76444525]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.random.rand(4,5,6)\n",
    "first = np.array([0,1,2])\n",
    "second = np.array([2,3,1])\n",
    "\n",
    "res = data[first, second]\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'h5File' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-1eedfb7a4c08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mh5py_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sentences\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstring_dt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mh5File\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mh5File\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'xxx.h5'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'h5File' is not defined"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "def create_dataset(h5py_file, string_list):\n",
    "    data = np.array([['I', 'am', 'a', 'sentence'], ['another', 'sentence']], dtype=object)\n",
    "    string_dt = h5py.special_dtype(vlen=str)\n",
    "    h5py_file.create_dataset(\"sentences\", data=data, dtype=string_dt)\n",
    "    \n",
    "h5File.close()\n",
    "h5File=h5py.File('xxx.h5','w')\n",
    "\n",
    "create_dataset(h5File)\n",
    "h5File.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.]\n",
      " [ 0.  1.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "aa =  np.eye(5)\n",
    "print aa[np.array([1,3,1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator annotation json (may be done already)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "from proj_utils.local_utils import *\n",
    "\n",
    "Data_root = os.path.join('..','..','..', 'Data', 'bladder_data')\n",
    "save_root = os.path.join('..','..','..', 'Data', 'bladder_data')\n",
    "\n",
    "annotation_folder = os.path.join(Data_root, 'Annotation')\n",
    "Img_folder = os.path.join(Data_root, 'Img') \n",
    "\n",
    "\n",
    "hdf5_filepath = os.path.join(save_root, 'images_caption.h5')\n",
    "hdf5_ref_filepath = os.path.join(save_root, 'images_caption_ref.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_identifier(name):\n",
    "    idx = name.find('augment')\n",
    "    if idx == -1:\n",
    "        return name\n",
    "    else:\n",
    "        ident = name[0:idx - 1]\n",
    "        return ident\n",
    "with h5py.File(hdf5_filepath,'a') as ImgHdf5:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50008\n"
     ]
    }
   ],
   "source": [
    "output_json = os.path.join(save_root,'total_anno.json') \n",
    "\n",
    "anno_filelist, anno_filenames = getfilelist(annotation_folder,['.json'] )\n",
    "\n",
    "total_num = len(anno_filelist)\n",
    "print(total_num)\n",
    "\n",
    "total_json = []\n",
    "test_num = total_num\n",
    "\n",
    "# pool for one hot label\n",
    "n_labels = 4\n",
    "one_hot = np.eye(n_labels).astype(np.int)\n",
    "def get_cnn_img(thisimg, shape, norm=False):\n",
    "    ''' \n",
    "    Parameters:\n",
    "    -----------\n",
    "    shape, (row, col, channel).\n",
    "    norm: if you preder to normalize iter\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    img: Tensor of shape(channel, row, col)\n",
    "\n",
    "    '''\n",
    "    if isinstance(thisimg, np.ndarray):\n",
    "        img = thisimg\n",
    "    elif type(thisimg) is str:\n",
    "        img = imread(thisimg)\n",
    "    img  = pre_process_img(img, yuv = False, norm= norm)  #(img, yuv = False,norm= local_norm)\n",
    "\n",
    "    img =  imresize_shape(img,shape)\n",
    "    # transpose the img to order (channel, row, col)\n",
    "    img = np.transpose(img, (2,0,1))\n",
    "    return img\n",
    "\n",
    "def parse_anno(anno_dict_list):\n",
    "\n",
    "    str_list = []\n",
    "    if type(anno_dict_list) is not list:\n",
    "        anno_dict_list = [anno_dict_list]\n",
    "    for anno_dict in anno_dict_list:         \n",
    "        thisstr = ''\n",
    "        for k, v in anno_dict.items():\n",
    "            thisstr = thisstr + ' '+ k.title() +': '\n",
    "            thisstr  = thisstr + ' ' + v[1]\n",
    "        str_list.append(thisstr)\n",
    "    return str_list\n",
    "\n",
    "\n",
    "with h5py.File(hdf5_filepath,'w') as ImgHdf5:\n",
    "    #dset_img = ImgHdf5.create_dataset(\"images\", (total_num, 3, 224, 224), dtype='uint8')\n",
    "    dset_img = ImgHdf5.create_dataset(\"images\", (total_num, 3, 224, 224), dtype='uint8')\n",
    "\n",
    "    dset_conclusion = ImgHdf5.create_dataset(\"conclusion\", (total_num, n_labels), dtype='int')\n",
    "\n",
    "    string_dt = h5py.special_dtype(vlen=str)\n",
    "\n",
    "    sentence_list  = []\n",
    "    filename_list = []\n",
    "    filename_dict = {}\n",
    "\n",
    "    for idx, (fp, fn) in enumerate(zip(anno_filelist, anno_filenames )): \n",
    "        if idx == test_num:\n",
    "            break\n",
    "\n",
    "        img_name = fn + '.png'\n",
    "        thisimg = imread(os.path.join(Img_folder, img_name))\n",
    "        filename_dict[fn] = idx\n",
    "\n",
    "        new_img  = get_cnn_img(thisimg, (224, 224,3), norm=False).astype(np.uint8)\n",
    "\n",
    "        with open(fp) as data_file:    \n",
    "            thisjson = json.load(data_file)\n",
    "        sentence_list.append(parse_anno(thisjson)) \n",
    "        filename_list.append(fn)\n",
    "\n",
    "        this_conclusion = thisjson[0]['conclusion'][0] #not beautiful\n",
    "        dset_img[idx] = new_img\n",
    "        dset_conclusion[idx] = one_hot[this_conclusion]\n",
    "\n",
    "\n",
    "    sentence_data = np.array(sentence_list, dtype=object)\n",
    "    ImgHdf5.create_dataset(\"sentences\", data=sentence_data, dtype=string_dt)\n",
    "\n",
    "    filename_data = np.array(filename_list, dtype= object)\n",
    "    ImgHdf5.create_dataset(\"filenames\", data=filename_data, dtype=string_dt)\n",
    "    ImgHdf5.close()\n",
    "\n",
    "    with open(hdf5_ref_filepath,'w') as f:\n",
    "        json.dump(filename_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with h5py.File(hdf5_filepath,'w') as ImgHdf5:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and test the hdf5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50008, 3, 224, 224)\n",
      "(50008, 5)\n",
      "[ ' Polarity:  Polarity is negligibly lost. Nucleoli:  The nucleoli of nuclei are inconspicuous. Nuclear_Feature:  The nuclei are moderately pleomorphic. Mitosis:  There are rarely mitotic figures throughout the tissue. Nuclear_Crowding:  Nuclei are moderately crowded together. Conclusion:  Lg / punlmp.'\n",
      " ' Polarity:  Basement membrane polarity is negligibly lost. Nucleoli:  The nucleoli of nuclei are inconspicuous. Nuclear_Feature:  Moderate pleomorphism of the nuclei can be seen. Mitosis:  Mitosis is rare. Nuclear_Crowding:  Moderate nuclear crowding is present. Conclusion:  Lg / punlmp.'\n",
      " ' Polarity:  Polarity of nuclei is negligibly lost. Nucleoli:  The nucleoli are mostly inconspicuous. Nuclear_Feature:  Moderate pleomorphism is present in the nuclei. Mitosis:  Mitotic figures are rare. Nuclear_Crowding:  The nuclei are moderately crowded. Conclusion:  Lg / punlmp.'\n",
      " ' Polarity:  Polarity is negligibly lost. Nucleoli:  The nuclei have inconspicuous nucleoli. Nuclear_Feature:  Moderate pleomorphism of the nuclei can be seen. Mitosis:  There are rarely mitotic figures throughout the tissue. Nuclear_Crowding:  The nuclei are crowded to a moderate degree. Conclusion:  Lg / punlmp.'\n",
      " ' Polarity:  Basement membrane polarity is negligibly lost. Nucleoli:  The nuclei have inconspicuous nucleoli. Nuclear_Feature:  The nuclei exhibit moderate pleomorphism. Mitosis:  Mitosis appears to be rare. Nuclear_Crowding:  The nuclei are crowded to a moderate degree. Conclusion:  Lg / punlmp.']\n",
      "-----------------\n",
      " Polarity:  Polarity is negligibly lost. Nucleoli:  The nucleoli of nuclei are inconspicuous. Nuclear_Feature:  The nuclei are moderately pleomorphic. Mitosis:  There are rarely mitotic figures throughout the tissue. Nuclear_Crowding:  Nuclei are moderately crowded together. Conclusion:  Lg / punlmp.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "import sys\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "#from utils.local_utils import *\n",
    "\n",
    "Data_root = os.path.join('..','..', 'Data', 'bladder_data')\n",
    "annotation_folder = os.path.join(Data_root, 'Annotation') \n",
    "Img_folder = os.path.join(Data_root, 'Img') \n",
    "\n",
    "output_json = os.path.join(Data_root,'total_anno.json') \n",
    "\n",
    "# anno_filelist, anno_filenames = getfilelist(annotation_folder,['.json'] )\n",
    "\n",
    "# total_num = len(anno_filelist)\n",
    "# print(total_num)\n",
    "\n",
    "# total_json = []\n",
    "# test_num = total_num\n",
    "\n",
    "# # pool for one hot label\n",
    "# n_labels = 4\n",
    "# one_hot = np.eye(n_labels).astype(np.int)\n",
    "\n",
    "\n",
    "hdf5_filepath = os.path.join(Data_root, 'images_caption.h5')\n",
    "\n",
    "\n",
    "with h5py.File(hdf5_filepath,'r') as testh5:\n",
    "    imgs = testh5['images']\n",
    "    sents = testh5['sentences']\n",
    "    labs  = testh5['conclusion']\n",
    "    fns   = testh5['filenames']\n",
    "    \n",
    "    print(imgs.shape)\n",
    "    print(sents.shape)\n",
    "    sents_list = sents.value[[1,3,1,4]]\n",
    "    this_sent = sents_list[0]\n",
    "    print(this_sent)\n",
    "    print('-----------------')\n",
    "    print(this_sent[0])\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import json\n",
    "import re\n",
    "\n",
    "def split_words(words):\n",
    "    return re.findall(r'\\w+|\\S+', words)\n",
    "\n",
    "save_root = os.path.join('..','..', 'Data', 'bladder_data')\n",
    "\n",
    "dict_path = os.path.join(save_root,'dictionary.json')\n",
    "worddict = OrderedDict()\n",
    "worddict['<eos>'] = 0\n",
    "worddict['UNK'] = 1\n",
    "wordIndex = 2\n",
    "\n",
    "Dicts = {}\n",
    "\n",
    "\n",
    "with h5py.File(hdf5_filepath,'r') as testh5:\n",
    "    imgs = testh5['images']\n",
    "    sents = testh5['sentences']\n",
    "    labs  = testh5['conclusion']\n",
    "    fns   = testh5['filenames']\n",
    "    all_sents = sents.value\n",
    "    for this_list in all_sents:\n",
    "        for this_sent in this_list:\n",
    "            this_sent = this_sent.decode()\n",
    "            words = split_words(this_sent)\n",
    "            for k in words:\n",
    "                if k not in worddict:\n",
    "                    worddict[k] = wordIndex\n",
    "                    wordIndex = wordIndex + 1\n",
    "\n",
    "word_idict = dict()\n",
    "for kk, vv in worddict.items():\n",
    "    word_idict[vv] = kk\n",
    "word_idict[0] = '<eos>'\n",
    "word_idict[1] = 'UNK'\n",
    "\n",
    "Dicts['encoder'] = worddict\n",
    "Dicts['decoder'] = word_idict\n",
    "with open(dict_path,'w') as f:\n",
    "    json.dump(Dicts, f)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1  1\n",
      " 3  1\n",
      " 3  2\n",
      " 2  2\n",
      "[torch.LongTensor of size 4x2]\n",
      "\n",
      "\n",
      " 1  0  0  0\n",
      " 0  1  0  0\n",
      " 0  0  0  1\n",
      " 0  1  0  0\n",
      " 0  0  1  0\n",
      "[torch.cuda.FloatTensor of size 5x4 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torch.autograd import Variable\n",
    "def to_variable(x, requires_grad=False, cuda=False):\n",
    "    if type(x) is Variable:\n",
    "        return x\n",
    "    if type(x) is np.ndarray:\n",
    "        x = torch.from_numpy(x)\n",
    "    if cuda:\n",
    "       return Variable(x, requires_grad=requires_grad).cuda()\n",
    "    else:\n",
    "       return Variable(x, requires_grad=requires_grad) \n",
    "\n",
    "def to_device(src, ref=None, var = True):\n",
    "    \n",
    "    src = to_variable(src) if var else src\n",
    "    return src.cuda(ref.get_device()) if (ref is not None and ref.is_cuda) else src\n",
    "\n",
    "def one_hot(nwords, ref=None):\n",
    "    eye_tensor = to_device(torch.eye(nwords),ref, var=False)\n",
    "    def f(tensor_int):\n",
    "        if type(tensor_int) is int:\n",
    "            tensor_int  = [tensor_int]\n",
    "        if type(tensor_int) is list :\n",
    "            tensor_int = torch.LongTensor(tensor_int)\n",
    "        tensor_int = to_device(tensor_int, ref, var=False)\n",
    "        size = list(tensor_int.size()) \n",
    "        flat = tensor_int.view(-1)\n",
    "        flat_emb = torch.index_select(eye_tensor, 0, flat)\n",
    "        new_shape = size + [nwords]\n",
    "        emb = flat_emb.view(*new_shape)\n",
    "        return Variable(emb)\n",
    "    return f\n",
    "\n",
    "Input = torch.Tensor([ [1,1],[3,1],[3,2],[2,2]]).long()\n",
    "ref = Input.cuda()\n",
    "print(Input)\n",
    "\n",
    "emb = one_hot(4, ref)\n",
    "res = emb([0,1,3,1,2])\n",
    "print(res.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "np.mod(batch_count, args.validfreq) == 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print coco.keys()\n",
    "print type(coco['images'])\n",
    "print type(coco['dataset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'sentids': [770337, 771687, 772707, 776154, 781998], u'filepath': u'val2014', u'filename': u'COCO_val2014_000000391895.jpg', u'imgid': 0, u'split': u'test', u'sentences': [{u'tokens': [u'a', u'man', u'with', u'a', u'red', u'helmet', u'on', u'a', u'small', u'moped', u'on', u'a', u'dirt', u'road'], u'raw': u'A man with a red helmet on a small moped on a dirt road. ', u'imgid': 0, u'sentid': 770337}, {u'tokens': [u'man', u'riding', u'a', u'motor', u'bike', u'on', u'a', u'dirt', u'road', u'on', u'the', u'countryside'], u'raw': u'Man riding a motor bike on a dirt road on the countryside.', u'imgid': 0, u'sentid': 771687}, {u'tokens': [u'a', u'man', u'riding', u'on', u'the', u'back', u'of', u'a', u'motorcycle'], u'raw': u'A man riding on the back of a motorcycle.', u'imgid': 0, u'sentid': 772707}, {u'tokens': [u'a', u'dirt', u'path', u'with', u'a', u'young', u'person', u'on', u'a', u'motor', u'bike', u'rests', u'to', u'the', u'foreground', u'of', u'a', u'verdant', u'area', u'with', u'a', u'bridge', u'and', u'a', u'background', u'of', u'cloud', u'wreathed', u'mountains'], u'raw': u'A dirt path with a young person on a motor bike rests to the foreground of a verdant area with a bridge and a background of cloud-wreathed mountains. ', u'imgid': 0, u'sentid': 776154}, {u'tokens': [u'a', u'man', u'in', u'a', u'red', u'shirt', u'and', u'a', u'red', u'hat', u'is', u'on', u'a', u'motorcycle', u'on', u'a', u'hill', u'side'], u'raw': u'A man in a red shirt and a red hat is on a motorcycle on a hill side.', u'imgid': 0, u'sentid': 781998}], u'cocoid': 391895}\n",
      "---------------\n",
      "coco\n",
      "---------------\n",
      "[u'sentids', u'filepath', u'filename', u'imgid', u'split', u'sentences', u'cocoid']\n",
      "---------------\n",
      "[{u'tokens': [u'a', u'man', u'with', u'a', u'red', u'helmet', u'on', u'a', u'small', u'moped', u'on', u'a', u'dirt', u'road'], u'raw': u'A man with a red helmet on a small moped on a dirt road. ', u'imgid': 0, u'sentid': 770337}, {u'tokens': [u'man', u'riding', u'a', u'motor', u'bike', u'on', u'a', u'dirt', u'road', u'on', u'the', u'countryside'], u'raw': u'Man riding a motor bike on a dirt road on the countryside.', u'imgid': 0, u'sentid': 771687}, {u'tokens': [u'a', u'man', u'riding', u'on', u'the', u'back', u'of', u'a', u'motorcycle'], u'raw': u'A man riding on the back of a motorcycle.', u'imgid': 0, u'sentid': 772707}, {u'tokens': [u'a', u'dirt', u'path', u'with', u'a', u'young', u'person', u'on', u'a', u'motor', u'bike', u'rests', u'to', u'the', u'foreground', u'of', u'a', u'verdant', u'area', u'with', u'a', u'bridge', u'and', u'a', u'background', u'of', u'cloud', u'wreathed', u'mountains'], u'raw': u'A dirt path with a young person on a motor bike rests to the foreground of a verdant area with a bridge and a background of cloud-wreathed mountains. ', u'imgid': 0, u'sentid': 776154}, {u'tokens': [u'a', u'man', u'in', u'a', u'red', u'shirt', u'and', u'a', u'red', u'hat', u'is', u'on', u'a', u'motorcycle', u'on', u'a', u'hill', u'side'], u'raw': u'A man in a red shirt and a red hat is on a motorcycle on a hill side.', u'imgid': 0, u'sentid': 781998}]\n",
      "---------------\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "print coco['images'][0]\n",
    "print('---------------')\n",
    "print coco['dataset']\n",
    "print('---------------')\n",
    "print(coco['images'][0].keys())\n",
    "print('---------------')\n",
    "print coco['images'][0]['sentences']\n",
    "print('---------------')\n",
    "print coco['images'][0]['split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bladder = json.load(open('../../Data/bladder/caption_datasets/dataset_coco.json', 'r'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
