{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lets download the annotations from http://mscoco.org/dataset/#download\n",
    "import os\n",
    "import json\n",
    "coco = json.load(open('../../Data/neural_talk_data/caption_datasets/dataset_coco.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H7_18_2\n",
      "8\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "name = \"H7_18_2_augment_42\"\n",
    "idx = name.find('augment')\n",
    "ident = name[0:idx-1]\n",
    "print(ident)\n",
    "print(name.find('augment'))\n",
    "\n",
    "naked = \"H7_18_2\"\n",
    "print(naked.find('augment'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from copy import copy\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "    \n",
    "def cumprod(inputs, dim = 1, exclusive=True):\n",
    "    # https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/api_docs/python/functions_and_classes/shard0/tf.cumprod.md\n",
    "\n",
    "    if type(inputs) is not Variable:\n",
    "        temp = torch.cumprod(inputs, dim)\n",
    "        if not exclusive:\n",
    "            return temp\n",
    "        else:\n",
    "            temp =  temp / (inputs[0].expand_as(temp) + 1e-8)\n",
    "            temp[-1] = temp[-1]/(inputs[-1]+1e-8)\n",
    "            return temp\n",
    "    else:\n",
    "        shape_ = inputs.size()\n",
    "        ndim = len(shape_)\n",
    "        n_slot = shape_[dim]\n",
    "        output = Variable(inputs.data.new(*shape_).fill_(1.0), requires_grad = True)\n",
    "        slice_ = [slice(0,None,1) for _ in range(ndim)]\n",
    "        results = [[]] * n_slot\n",
    "            \n",
    "        for ind in range(0, n_slot):   \n",
    "            this_slice, last_slice = copy(slice_), copy(slice_)\n",
    "            this_slice[dim] = ind\n",
    "            last_slice[dim] = ind-1      \n",
    "            this_slice = tuple(this_slice)\n",
    "            last_slice = tuple(last_slice)\n",
    "            if exclusive: \n",
    "                if ind > 0:   \n",
    "                    results[ind]  = results[ind-1]*inputs[last_slice]\n",
    "                else:\n",
    "                    results[ind] =  torch.div(inputs[this_slice], inputs[this_slice]+1e-8)\n",
    "            else:    \n",
    "                if ind > 0:   \n",
    "                    results[ind]  = results[ind - 1]*inputs[this_slice]\n",
    "                else:\n",
    "                    results[ind] =  inputs[this_slice]\n",
    "        \n",
    "        return torch.stack(results, dim)\n",
    "\n",
    "\n",
    "\n",
    "W = nn.Parameter(torch.Tensor(4,7,10))\n",
    "\n",
    "data_pre = data_var * W\n",
    "#print(data)\n",
    "#result = cumprod(data, 1, True)\n",
    "result_var = cumprod(data_pre)\n",
    "\n",
    "#print(result_var)\n",
    "\n",
    "loss = torch.sum(result_var) *0.5\n",
    "loss.backward()\n",
    "\n",
    "print(W.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(0 ,.,.) = \n",
      "\n",
      "Columns 0 to 5 \n",
      "   1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00\n",
      "  2.7183e-01  5.1821e-01  3.1315e-01  6.0220e-01  2.1070e-01  5.1511e-02\n",
      "  1.2155e-02  4.0495e-02  9.5343e-02  5.3563e-02  9.2726e-02  1.1480e-02\n",
      "  1.3138e-03  2.0646e-02  3.0269e-02  1.9387e-03  8.6944e-02  1.8767e-03\n",
      "  2.4156e-04  1.3680e-02  2.6423e-02  7.9429e-04  1.9606e-02  8.3287e-05\n",
      "  8.9345e-05  2.5854e-03  1.2000e-02  3.6397e-04  1.4546e-02  6.3052e-05\n",
      "  8.0057e-05  1.0126e-03  2.1515e-04  1.2945e-04  4.1774e-03  3.5443e-06\n",
      "\n",
      "Columns 6 to 9 \n",
      "   1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00\n",
      "  3.2066e-01  7.5134e-01  2.1201e-01  8.7637e-01\n",
      "  2.3872e-02  1.0548e-01  1.1280e-01  7.0206e-02\n",
      "  1.3599e-02  3.7222e-02  1.7532e-02  2.9286e-02\n",
      "  1.0159e-02  2.0240e-02  1.0189e-02  2.6916e-02\n",
      "  5.5381e-03  1.0313e-02  1.0006e-02  1.0428e-02\n",
      "  5.0010e-03  4.2063e-03  7.3943e-03  8.1591e-03\n",
      "\n",
      "(1 ,.,.) = \n",
      "\n",
      "Columns 0 to 5 \n",
      "   3.1102e+00  1.7116e+00  6.2718e-01  6.4754e-01  3.7530e+00  8.7979e-01\n",
      "  5.5905e+00  1.2231e+00  3.7292e-01  3.5974e+00  8.9478e-01  1.1020e-01\n",
      "  1.2270e+00  1.5609e-01  7.6883e-03  1.7781e+00  3.8828e-03  2.8153e-02\n",
      "  2.1390e-01  8.1765e-02  2.3040e-03  4.7577e-03  1.3954e-02  3.1947e-02\n",
      "  3.7979e-02  1.7594e-01  5.9495e-04  3.8058e-03  3.9516e-03  1.0304e-03\n",
      "  3.9810e-03  6.8079e-03  4.4611e-03  4.5354e-03  7.6552e-03  2.0281e-03\n",
      "  1.5239e-02  4.3820e-03  4.9661e-05  8.2166e-04  7.4199e-03  4.8445e-05\n",
      "\n",
      "Columns 6 to 9 \n",
      "   7.6046e-01  2.8987e-01  3.5399e+00  9.9826e-01\n",
      "  2.8555e+00  1.0447e-01  1.0715e+00  1.0269e+01\n",
      "  1.5451e-01  3.3706e-02  5.7541e-01  5.8980e-01\n",
      "  4.5653e-02  6.8560e-04  3.2547e-02  1.7432e-01\n",
      "  3.4490e-02  7.5328e-05  1.4908e-03  1.2089e-01\n",
      "  1.3265e-02  7.1092e-05  7.1976e-05  5.4370e-02\n",
      "  1.1227e-02  8.6258e-05  4.9406e-04  2.0945e-01\n",
      "\n",
      "(2 ,.,.) = \n",
      "\n",
      "Columns 0 to 5 \n",
      "   9.3951e-01  4.3942e-01  9.4962e-03  8.5137e-01  2.5358e+00  1.8390e+01\n",
      "  5.5590e+00  8.9915e-01  6.4632e-03  1.5108e+00  1.8430e-03  1.6987e+00\n",
      "  9.5617e-01  2.6210e-02  2.1250e-04  3.6348e+00  5.2520e-04  2.2683e+00\n",
      "  1.8114e-01  3.1619e-03  1.7529e-05  7.0759e-02  1.2218e-03  7.6606e+00\n",
      "  3.4569e-02  5.3620e-03  2.4597e-05  1.7246e-02  2.7212e-04  4.0467e-01\n",
      "  3.7882e-03  1.7860e-03  4.1447e-04  6.1549e-03  2.8107e-04  3.0506e+00\n",
      "  5.8319e-03  1.4324e-03  9.3835e-06  1.7223e-03  5.9430e-05  1.2369e-01\n",
      "\n",
      "Columns 6 to 9 \n",
      "   7.9578e-01  7.0296e-01  1.2830e+00  5.6644e-01\n",
      "  7.1186e-01  3.7574e+00  1.0016e-01  2.2607e+00\n",
      "  3.5831e-02  6.6510e-01  1.1567e-01  3.4175e-01\n",
      "  1.7815e-02  9.5024e-02  8.5532e-03  2.0051e-02\n",
      "  8.2615e-03  5.4938e-02  1.7622e-03  9.3075e-03\n",
      "  4.9702e-03  2.3482e-02  1.3610e-03  9.7026e-04\n",
      "  2.0839e-03  3.2396e-03  5.5045e-03  5.5329e-03\n",
      "\n",
      "(3 ,.,.) = \n",
      "\n",
      "Columns 0 to 5 \n",
      "   3.6788e+00  1.9297e+00  3.1934e+00  1.6606e+00  4.7461e+00  1.9413e+01\n",
      "  4.5170e+00  7.7608e-01  1.0984e+00  7.9564e+00  1.4920e+00  4.4648e+00\n",
      "  5.8362e-01  3.4803e-02  3.2370e-01  1.9272e+01  6.8414e-01  3.2265e+00\n",
      "  1.6284e-01  5.0409e-03  5.6939e-02  8.1305e-01  4.1989e-01  1.1118e+01\n",
      "  3.3974e-02  9.2036e-04  8.6015e-02  2.6923e-01  1.0011e-01  4.3742e-01\n",
      "  5.6159e-03  8.0777e-05  1.2972e-01  3.0248e-01  1.0727e-01  3.2414e+00\n",
      "  1.3368e-02  6.3822e-05  1.0002e-03  8.4706e-02  9.9514e-02  6.1747e-02\n",
      "\n",
      "Columns 6 to 9 \n",
      "   3.1186e+00  1.3310e+00  4.7168e+00  1.1411e+00\n",
      "  1.4924e-02  3.0267e+00  9.7392e-01  4.8641e+00\n",
      "  7.4121e-04  8.2221e-01  2.5174e+00  3.9096e-01\n",
      "  3.1464e-04  1.8705e-02  6.6876e-01  1.5326e-01\n",
      "  2.6240e-04  1.2639e-03  1.1804e-01  2.6431e-01\n",
      "  6.9064e-06  1.0137e-03  6.2137e-02  9.6107e-02\n",
      "  1.8172e-05  2.0574e-06  3.2468e-01  4.8982e-01\n",
      "[torch.FloatTensor of size 4x7x10]\n",
      " Variable containing:\n",
      "(0 ,.,.) = \n",
      "\n",
      "Columns 0 to 5 \n",
      "   1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00\n",
      "  2.7183e-01  5.1821e-01  3.1315e-01  6.0220e-01  2.1070e-01  5.1511e-02\n",
      "  1.2155e-02  4.0495e-02  9.5343e-02  5.3563e-02  9.2726e-02  1.1480e-02\n",
      "  1.3138e-03  2.0646e-02  3.0269e-02  1.9387e-03  8.6944e-02  1.8767e-03\n",
      "  2.4156e-04  1.3680e-02  2.6423e-02  7.9429e-04  1.9606e-02  8.3287e-05\n",
      "  8.9345e-05  2.5854e-03  1.2000e-02  3.6397e-04  1.4546e-02  6.3052e-05\n",
      "  8.0057e-05  1.0126e-03  2.1515e-04  1.2945e-04  4.1774e-03  3.5443e-06\n",
      "\n",
      "Columns 6 to 9 \n",
      "   1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00\n",
      "  3.2066e-01  7.5134e-01  2.1201e-01  8.7637e-01\n",
      "  2.3872e-02  1.0548e-01  1.1280e-01  7.0206e-02\n",
      "  1.3599e-02  3.7222e-02  1.7532e-02  2.9286e-02\n",
      "  1.0159e-02  2.0240e-02  1.0189e-02  2.6916e-02\n",
      "  5.5381e-03  1.0313e-02  1.0006e-02  1.0428e-02\n",
      "  5.0010e-03  4.2063e-03  7.3943e-03  8.1591e-03\n",
      "\n",
      "(1 ,.,.) = \n",
      "\n",
      "Columns 0 to 5 \n",
      "   1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00\n",
      "  8.4543e-01  8.8695e-01  1.9640e-01  3.8995e-01  7.9076e-01  4.5319e-02\n",
      "  2.4998e-01  9.5578e-02  1.1354e-01  3.1997e-01  3.9378e-01  2.4558e-02\n",
      "  1.3263e-01  7.9581e-02  2.4409e-03  6.4358e-02  3.6406e-03  4.6026e-03\n",
      "  3.9328e-02  5.4178e-02  2.0112e-03  1.9493e-03  3.1467e-03  1.4178e-03\n",
      "  1.4047e-02  3.3250e-02  2.7021e-04  1.7439e-03  2.9317e-03  7.8003e-04\n",
      "  3.5672e-03  2.6664e-03  7.9982e-05  1.6131e-03  2.1985e-03  1.1400e-04\n",
      "\n",
      "Columns 6 to 9 \n",
      "   1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00\n",
      "  2.4385e-01  2.1779e-01  7.5049e-01  8.7484e-01\n",
      "  2.1258e-01  1.4667e-02  5.7010e-01  8.2267e-01\n",
      "  8.8021e-02  1.1894e-02  8.9434e-02  2.4603e-01\n",
      "  3.4102e-02  3.7280e-04  1.8915e-02  1.6021e-01\n",
      "  1.8803e-02  3.8384e-05  1.4640e-03  4.6837e-02\n",
      "  1.1978e-02  2.8994e-05  5.3191e-05  4.2540e-02\n",
      "\n",
      "(2 ,.,.) = \n",
      "\n",
      "Columns 0 to 5 \n",
      "   1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00\n",
      "  2.5538e-01  2.2772e-01  2.9737e-03  5.1269e-01  5.3429e-01  9.4731e-01\n",
      "  2.4857e-01  7.0264e-02  1.9678e-03  1.3438e-01  8.1108e-04  3.7856e-01\n",
      "  1.0336e-01  1.3363e-02  6.7465e-05  1.3156e-01  4.9245e-04  3.7083e-01\n",
      "  3.3305e-02  2.0951e-03  1.5301e-05  2.8991e-02  2.7552e-04  3.3997e-01\n",
      "  1.2786e-02  1.0134e-03  1.1171e-05  7.9027e-03  2.0189e-04  3.0635e-01\n",
      "  3.3944e-03  6.9951e-04  7.4309e-06  2.1891e-03  8.0722e-05  1.7148e-01\n",
      "\n",
      "Columns 6 to 9 \n",
      "   1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00\n",
      "  2.5517e-01  5.2816e-01  2.7200e-01  4.9641e-01\n",
      "  5.2996e-02  5.2752e-01  5.3288e-02  1.8111e-01\n",
      "  2.0412e-02  2.3469e-01  1.7978e-02  1.4256e-01\n",
      "  1.3307e-02  5.1670e-02  4.9708e-03  1.8429e-02\n",
      "  4.5039e-03  2.7994e-02  1.7305e-03  3.6059e-03\n",
      "  4.4882e-03  9.5771e-03  1.0058e-03  7.5916e-04\n",
      "\n",
      "(3 ,.,.) = \n",
      "\n",
      "Columns 0 to 5 \n",
      "   1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00\n",
      "  2.0198e-01  6.0646e-02  3.3443e-01  7.0769e-01  6.5659e-01  9.9500e-01\n",
      "  6.3085e-02  1.7744e-02  1.0277e-01  6.9753e-01  6.4148e-01  5.2749e-01\n",
      "  2.9940e-02  3.3401e-03  4.9703e-02  3.3311e-01  9.4685e-02  4.9339e-01\n",
      "  1.2566e-02  1.7394e-04  3.9065e-02  1.2337e-01  7.4273e-02  3.3114e-01\n",
      "  5.0321e-03  3.1637e-05  2.3256e-03  1.0758e-01  3.0807e-02  1.8221e-01\n",
      "  2.4684e-03  2.9377e-05  7.7440e-04  6.4017e-02  1.7665e-02  4.9963e-02\n",
      "\n",
      "Columns 6 to 9 \n",
      "   9.9999e-01  1.0000e+00  1.0000e+00  1.0000e+00\n",
      "  1.1111e-03  4.2493e-01  5.1818e-01  3.8967e-01\n",
      "  4.2225e-04  2.9014e-01  3.9127e-01  1.6308e-01\n",
      "  2.3503e-04  1.0171e-02  3.8866e-01  1.4086e-01\n",
      "  1.4305e-04  6.4404e-04  1.1591e-01  1.0240e-01\n",
      "  6.2364e-06  4.1345e-04  4.5920e-02  7.5197e-02\n",
      "  2.8258e-06  4.1054e-07  3.0979e-02  4.2164e-02\n",
      "[torch.FloatTensor of size 4x7x10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "data = torch.rand(4,7,10)\n",
    "\n",
    "data_var = Variable(data)\n",
    "\n",
    "result = cumprod(data, 1, True)\n",
    "result_var = cumprod(data_var)\n",
    "\n",
    "print(result, result_var)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "(0 ,.,.) = \n",
      "\n",
      "Columns 0 to 5 \n",
      "   1.3591e-01  2.5911e+07  1.5657e-01  3.0110e+07  1.0535e+07  2.5756e+06\n",
      " -1.6945e+08  0.0000e+00 -1.3292e+09  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "\n",
      "Columns 6 to 9 \n",
      "   1.6033e+07  3.7567e+07  1.0600e+07  4.3818e+07\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "\n",
      "(1 ,.,.) = \n",
      "\n",
      "Columns 0 to 5 \n",
      "   4.2271e+07  4.4348e+07  9.8200e+06  1.9497e+07  3.9538e+07  2.2660e+06\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "\n",
      "Columns 6 to 9 \n",
      "   1.2192e+07  1.0890e+07  3.7525e+07  4.3742e+07\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "\n",
      "(2 ,.,.) = \n",
      "\n",
      "Columns 0 to 5 \n",
      "   1.2769e+07  1.1386e+07  1.4869e+05  2.5635e+07  2.6714e+07  4.7365e+07\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "\n",
      "Columns 6 to 9 \n",
      "   1.2759e+07  2.6408e+07  1.3600e+07  2.4821e+07\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "\n",
      "(3 ,.,.) = \n",
      "\n",
      "Columns 0 to 5 \n",
      "          nan  3.0323e+06  1.6721e+07  3.5385e+07  3.1913e+00  4.9750e+07\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00 -2.7454e+05  1.2130e-32\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00 -6.7185e-16  0.0000e+00\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  4.8220e-05  0.0000e+00\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "\n",
      "Columns 6 to 9 \n",
      "   5.5554e+04  2.1247e+07  2.5909e+07  1.9483e+07\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      "[torch.FloatTensor of size 4x7x10]\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(0 ,.,.) = \n",
      "  0.7615  0.5426\n",
      "  0.0270  0.2162\n",
      "  0.4347  0.5452\n",
      "\n",
      "(1 ,.,.) = \n",
      "  0.4225  0.8997\n",
      "  0.9161  0.7573\n",
      "  0.6608  0.1834\n",
      "\n",
      "(2 ,.,.) = \n",
      "  0.6764  0.6198\n",
      "  0.0159  0.6918\n",
      "  0.7290  0.8699\n",
      "\n",
      "(3 ,.,.) = \n",
      "  0.7890  0.4502\n",
      "  0.1355  0.5624\n",
      "  0.8061  0.9127\n",
      "[torch.FloatTensor of size 4x3x2]\n",
      "\n",
      "\n",
      " 0.7615  0.5426\n",
      " 0.0270  0.2162\n",
      " 0.4347  0.5452\n",
      " 0.4225  0.8997\n",
      " 0.9161  0.7573\n",
      " 0.6608  0.1834\n",
      " 0.6764  0.6198\n",
      " 0.0159  0.6918\n",
      " 0.7290  0.8699\n",
      " 0.7890  0.4502\n",
      " 0.1355  0.5624\n",
      " 0.8061  0.9127\n",
      "[torch.FloatTensor of size 12x2]\n",
      "\n",
      "\n",
      " 0.0270\n",
      " 0.2162\n",
      "[torch.FloatTensor of size 2]\n",
      "\n",
      "=================\n",
      "\n",
      " 0.0270  0.2162\n",
      " 0.6764  0.6198\n",
      " 0.6608  0.1834\n",
      "[torch.FloatTensor of size 3x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dat = torch.rand(4,3,2)\n",
    "row, col, dim = dat.size()\n",
    "\n",
    "print(dat)\n",
    "flat_dat = dat.view(-1,2)\n",
    "print(flat_dat)\n",
    "first = torch.LongTensor([0,2,1])\n",
    "second = torch.LongTensor([1,0,2])\n",
    "\n",
    "print(dat[0,1])\n",
    "index = first*col + second\n",
    "select = flat_dat[index]\n",
    "\n",
    "print('=================')\n",
    "print(select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 4, 20])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pad_packed_sequence as unpack\n",
    "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
    "\n",
    "def sort_batch(data, seq_len):\n",
    "    batch_size = data.size(0)\n",
    "    sorted_seq_len, sorted_idx  = torch.sort(seq_len, dim=0, descending=True)\n",
    "    sorted_data = data[sorted_idx]\n",
    "    _, reverse_idx  = torch.sort(sorted_idx, dim=0, descending=False)\n",
    "    return sorted_data, sorted_seq_len, reverse_idx\n",
    "\n",
    "data = torch.rand(4,7,10)\n",
    "lens = torch.LongTensor([3,7,2,1])\n",
    "\n",
    "s_data, s_len, reverse_idx = sort_batch(data, lens)\n",
    "\n",
    "emb = pack(Variable(s_data), list(s_len),batch_first=True)\n",
    "\n",
    "rnn = nn.LSTM(10, 20, 2, batch_first =True, bidirectional=False)\n",
    "input = emb\n",
    "h0 = Variable(torch.randn(2, 6, 20))\n",
    "c0 = Variable(torch.randn(2, 6, 20))\n",
    "packed_output, hn = rnn(input)\n",
    "result, lens = unpack(packed_output)\n",
    "print(result.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 7, 20])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pad_packed_sequence as unpack\n",
    "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
    "\n",
    "data = Variable(torch.rand(4,7,10))\n",
    "lens = torch.LongTensor([3,7,2,1])\n",
    "\n",
    "#s_data, s_len, reverse_idx = sort_batch(data, lens)\n",
    "\n",
    "rnn = nn.LSTM(10, 20, 2, batch_first =True, bidirectional=False)\n",
    "\n",
    "h0 = Variable(torch.randn(2, 6, 20))\n",
    "c0 = Variable(torch.randn(2, 6, 20))\n",
    "output, hn = rnn(data)\n",
    "\n",
    "#result, lens = unpack(packed_output)\n",
    "print(output.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "a = Variable(torch.Tensor([1]))\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "print(cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\n",
      " 6\n",
      " 2\n",
      " 1\n",
      " 0\n",
      "[torch.LongTensor of size 4]\n",
      ", \n",
      " 0\n",
      " 1\n",
      " 2\n",
      " 3\n",
      "[torch.LongTensor of size 4]\n",
      ")\n",
      "('result', torch.Size([7, 4, 20]))\n",
      "('last out', torch.Size([4, 20]))\n",
      "Variable containing:\n",
      "-0.0213  0.0501 -0.1353 -0.0388 -0.0474 -0.2192  0.0512 -0.1225\n",
      "-0.0184  0.0430 -0.1112 -0.0204 -0.0506 -0.1931  0.0632 -0.0996\n",
      "-0.0140  0.0469 -0.0929 -0.0135 -0.0487 -0.1604  0.0630 -0.0850\n",
      "-0.0202  0.0292 -0.0607  0.0021 -0.0313 -0.1138  0.0473 -0.0582\n",
      "[torch.FloatTensor of size 4x8]\n",
      "\n",
      "---------------\n",
      "Variable containing:\n",
      "(0 ,.,.) = \n",
      " -0.0203  0.0331 -0.0582  0.0013 -0.0381 -0.1165  0.0493 -0.0546\n",
      " -0.0086  0.0298 -0.0589 -0.0036 -0.0282 -0.1145  0.0368 -0.0562\n",
      " -0.0119  0.0327 -0.0614 -0.0033 -0.0302 -0.1074  0.0475 -0.0600\n",
      " -0.0202  0.0292 -0.0607  0.0021 -0.0313 -0.1138  0.0473 -0.0582\n",
      "\n",
      "(1 ,.,.) = \n",
      " -0.0281  0.0402 -0.0977 -0.0021 -0.0458 -0.1637  0.0722 -0.0916\n",
      " -0.0160  0.0365 -0.0948 -0.0093 -0.0365 -0.1666  0.0549 -0.0874\n",
      " -0.0140  0.0469 -0.0929 -0.0135 -0.0487 -0.1604  0.0630 -0.0850\n",
      "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "\n",
      "(2 ,.,.) = \n",
      " -0.0267  0.0469 -0.1205 -0.0196 -0.0441 -0.1895  0.0718 -0.1090\n",
      " -0.0184  0.0430 -0.1112 -0.0204 -0.0506 -0.1931  0.0632 -0.0996\n",
      "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "\n",
      "(3 ,.,.) = \n",
      " -0.0339  0.0497 -0.1261 -0.0254 -0.0534 -0.2031  0.0729 -0.1181\n",
      "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "\n",
      "(4 ,.,.) = \n",
      " -0.0332  0.0486 -0.1330 -0.0302 -0.0456 -0.2139  0.0659 -0.1257\n",
      "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "\n",
      "(5 ,.,.) = \n",
      " -0.0289  0.0496 -0.1346 -0.0340 -0.0479 -0.2163  0.0599 -0.1282\n",
      "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "\n",
      "(6 ,.,.) = \n",
      " -0.0213  0.0501 -0.1353 -0.0388 -0.0474 -0.2192  0.0512 -0.1225\n",
      "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "[torch.FloatTensor of size 7x4x8]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def two_ind(data, first, second):\n",
    "    '''\n",
    "    data: 3 dimension\n",
    "    first: 1 d tensor\n",
    "    second: 1 d tensor\n",
    "    '''\n",
    "    row, col, dim = data.size()\n",
    "    index = first*col + second\n",
    "    last_out = result.view(-1, dim)[index]\n",
    "    return last_out\n",
    "    \n",
    "lens_th = Variable(torch.LongTensor(lens))    \n",
    "first  = (lens_th -1).data \n",
    "second = torch.range(0, len(lens)-1).long()\n",
    "\n",
    "print(first, second)\n",
    "last_out = two_ind(result, first, second)\n",
    "#last_out = torch.index_select(torch.index_select(second, 0, lens_th-1), 1, second)\n",
    "#last_out = result[lens_th.data-1, :][:,second]\n",
    "                   \n",
    "print('result', result.size())\n",
    "print('last out',last_out.size())\n",
    "\n",
    "print(last_out[:,0:8])\n",
    "print('---------------')\n",
    "print(result[:, :, 0:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\n",
      "-1.5788  1.3199  1.7161  0.5836\n",
      " 0.9811  2.5551 -0.3949  0.9135\n",
      " 0.0840 -0.0228  1.3977 -1.0893\n",
      " 0.4723 -0.3251 -0.4061  1.2842\n",
      "-1.5411 -1.1587  0.8768  0.8281\n",
      "[torch.FloatTensor of size 5x4]\n",
      ", \n",
      "-1.0217  0.7216  0.3534 -0.9644\n",
      "-0.1993 -0.1303  0.6186  0.4552\n",
      " 0.2413  0.9452 -1.2923 -0.1830\n",
      " 0.4121  1.4143  0.4108  0.6924\n",
      " 0.6960  1.5349  1.8151  0.0185\n",
      "[torch.FloatTensor of size 5x4]\n",
      ")\n",
      "\n",
      " 0.5879\n",
      "-0.1524\n",
      "-0.5563\n",
      " 0.1860\n",
      "-0.2209\n",
      "[torch.FloatTensor of size 5x1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch1 = torch.randn(5, 4)\n",
    "batch2 = torch.randn(5, 4)\n",
    "\n",
    "print(batch1,batch2)\n",
    "\n",
    "def cosine_similarity(first, second):\n",
    "    \"\"\"\n",
    "    compute the cosine similarity between keys to each of the \n",
    "    memory slot.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    first: Tensor (batch_size, dim)\n",
    "        the memory matrix to lookup in\n",
    "    second: Tensor (batch_size, dim)\n",
    "        the keys to query the memory with\n",
    "    Returns: Tensor (batch_size, 1)\n",
    "    \"\"\"\n",
    "    first_norm  = torch.norm(first,  2, 1)\n",
    "    second_norm = torch.norm(second, 2, 1)\n",
    "\n",
    "    normalized_first  = torch.div(first,  first_norm.expand_as(first) + 1e-10)\n",
    "    normalized_second = torch.div(second, second_norm.expand_as(second) + 1e-10)\n",
    "\n",
    "    return torch.sum(normalized_first*normalized_second,1)\n",
    "\n",
    "cos = cosine_similarity(batch1, batch2)\n",
    "print(cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.48210773  0.752584    0.64944821  0.19314062  0.03171795  0.26378825]\n",
      " [ 0.14147113  0.4699371   0.66200108  0.78925308  0.94670398  0.18808383]\n",
      " [ 0.59918571  0.57468536  0.66673667  0.98518522  0.20246986  0.76444525]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.random.rand(4,5,6)\n",
    "first = np.array([0,1,2])\n",
    "second = np.array([2,3,1])\n",
    "\n",
    "res = data[first, second]\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'h5File' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-1eedfb7a4c08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mh5py_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sentences\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstring_dt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mh5File\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mh5File\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'xxx.h5'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'h5File' is not defined"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "def create_dataset(h5py_file, string_list):\n",
    "    data = np.array([['I', 'am', 'a', 'sentence'], ['another', 'sentence']], dtype=object)\n",
    "    string_dt = h5py.special_dtype(vlen=str)\n",
    "    h5py_file.create_dataset(\"sentences\", data=data, dtype=string_dt)\n",
    "    \n",
    "h5File.close()\n",
    "h5File=h5py.File('xxx.h5','w')\n",
    "\n",
    "create_dataset(h5File)\n",
    "h5File.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.]\n",
      " [ 0.  1.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "aa =  np.eye(5)\n",
    "print aa[np.array([1,3,1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator annotation json (may be done already)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "from proj_utils.local_utils import *\n",
    "\n",
    "Data_root = os.path.join('..','..','..', 'Data', 'bladder_data')\n",
    "save_root = os.path.join('..','..','..', 'Data', 'bladder_data')\n",
    "\n",
    "annotation_folder = os.path.join(Data_root, 'Annotation')\n",
    "Img_folder = os.path.join(Data_root, 'Img') \n",
    "\n",
    "\n",
    "hdf5_filepath = os.path.join(save_root, 'images_caption.h5')\n",
    "hdf5_ref_filepath = os.path.join(save_root, 'images_caption_ref.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_identifier(name):\n",
    "    idx = name.find('augment')\n",
    "    if idx == -1:\n",
    "        return name\n",
    "    else:\n",
    "        ident = name[0:idx - 1]\n",
    "        return ident\n",
    "with h5py.File(hdf5_filepath,'a') as ImgHdf5:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50008\n"
     ]
    }
   ],
   "source": [
    "output_json = os.path.join(save_root,'total_anno.json') \n",
    "\n",
    "anno_filelist, anno_filenames = getfilelist(annotation_folder,['.json'] )\n",
    "\n",
    "total_num = len(anno_filelist)\n",
    "print(total_num)\n",
    "\n",
    "total_json = []\n",
    "test_num = total_num\n",
    "\n",
    "# pool for one hot label\n",
    "n_labels = 4\n",
    "one_hot = np.eye(n_labels).astype(np.int)\n",
    "def get_cnn_img(thisimg, shape, norm=False):\n",
    "    ''' \n",
    "    Parameters:\n",
    "    -----------\n",
    "    shape, (row, col, channel).\n",
    "    norm: if you preder to normalize iter\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    img: Tensor of shape(channel, row, col)\n",
    "\n",
    "    '''\n",
    "    if isinstance(thisimg, np.ndarray):\n",
    "        img = thisimg\n",
    "    elif type(thisimg) is str:\n",
    "        img = imread(thisimg)\n",
    "    img  = pre_process_img(img, yuv = False, norm= norm)  #(img, yuv = False,norm= local_norm)\n",
    "\n",
    "    img =  imresize_shape(img,shape)\n",
    "    # transpose the img to order (channel, row, col)\n",
    "    img = np.transpose(img, (2,0,1))\n",
    "    return img\n",
    "\n",
    "def parse_anno(anno_dict_list):\n",
    "\n",
    "    str_list = []\n",
    "    if type(anno_dict_list) is not list:\n",
    "        anno_dict_list = [anno_dict_list]\n",
    "    for anno_dict in anno_dict_list:         \n",
    "        thisstr = ''\n",
    "        for k, v in anno_dict.items():\n",
    "            thisstr = thisstr + ' '+ k.title() +': '\n",
    "            thisstr  = thisstr + ' ' + v[1]\n",
    "        str_list.append(thisstr)\n",
    "    return str_list\n",
    "\n",
    "\n",
    "with h5py.File(hdf5_filepath,'w') as ImgHdf5:\n",
    "    #dset_img = ImgHdf5.create_dataset(\"images\", (total_num, 3, 224, 224), dtype='uint8')\n",
    "    dset_img = ImgHdf5.create_dataset(\"images\", (total_num, 3, 224, 224), dtype='uint8')\n",
    "\n",
    "    dset_conclusion = ImgHdf5.create_dataset(\"conclusion\", (total_num, n_labels), dtype='int')\n",
    "\n",
    "    string_dt = h5py.special_dtype(vlen=str)\n",
    "\n",
    "    sentence_list  = []\n",
    "    filename_list = []\n",
    "    filename_dict = {}\n",
    "\n",
    "    for idx, (fp, fn) in enumerate(zip(anno_filelist, anno_filenames )): \n",
    "        if idx == test_num:\n",
    "            break\n",
    "\n",
    "        img_name = fn + '.png'\n",
    "        thisimg = imread(os.path.join(Img_folder, img_name))\n",
    "        filename_dict[fn] = idx\n",
    "\n",
    "        new_img  = get_cnn_img(thisimg, (224, 224,3), norm=False).astype(np.uint8)\n",
    "\n",
    "        with open(fp) as data_file:    \n",
    "            thisjson = json.load(data_file)\n",
    "        sentence_list.append(parse_anno(thisjson)) \n",
    "        filename_list.append(fn)\n",
    "\n",
    "        this_conclusion = thisjson[0]['conclusion'][0] #not beautiful\n",
    "        dset_img[idx] = new_img\n",
    "        dset_conclusion[idx] = one_hot[this_conclusion]\n",
    "\n",
    "\n",
    "    sentence_data = np.array(sentence_list, dtype=object)\n",
    "    ImgHdf5.create_dataset(\"sentences\", data=sentence_data, dtype=string_dt)\n",
    "\n",
    "    filename_data = np.array(filename_list, dtype= object)\n",
    "    ImgHdf5.create_dataset(\"filenames\", data=filename_data, dtype=string_dt)\n",
    "    ImgHdf5.close()\n",
    "\n",
    "    with open(hdf5_ref_filepath,'w') as f:\n",
    "        json.dump(filename_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with h5py.File(hdf5_filepath,'w') as ImgHdf5:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and test the hdf5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50008, 3, 224, 224)\n",
      "(50008, 5)\n",
      "[ ' Polarity:  Polarity is negligibly lost. Nucleoli:  The nucleoli of nuclei are inconspicuous. Nuclear_Feature:  The nuclei are moderately pleomorphic. Mitosis:  There are rarely mitotic figures throughout the tissue. Nuclear_Crowding:  Nuclei are moderately crowded together. Conclusion:  Lg / punlmp.'\n",
      " ' Polarity:  Basement membrane polarity is negligibly lost. Nucleoli:  The nucleoli of nuclei are inconspicuous. Nuclear_Feature:  Moderate pleomorphism of the nuclei can be seen. Mitosis:  Mitosis is rare. Nuclear_Crowding:  Moderate nuclear crowding is present. Conclusion:  Lg / punlmp.'\n",
      " ' Polarity:  Polarity of nuclei is negligibly lost. Nucleoli:  The nucleoli are mostly inconspicuous. Nuclear_Feature:  Moderate pleomorphism is present in the nuclei. Mitosis:  Mitotic figures are rare. Nuclear_Crowding:  The nuclei are moderately crowded. Conclusion:  Lg / punlmp.'\n",
      " ' Polarity:  Polarity is negligibly lost. Nucleoli:  The nuclei have inconspicuous nucleoli. Nuclear_Feature:  Moderate pleomorphism of the nuclei can be seen. Mitosis:  There are rarely mitotic figures throughout the tissue. Nuclear_Crowding:  The nuclei are crowded to a moderate degree. Conclusion:  Lg / punlmp.'\n",
      " ' Polarity:  Basement membrane polarity is negligibly lost. Nucleoli:  The nuclei have inconspicuous nucleoli. Nuclear_Feature:  The nuclei exhibit moderate pleomorphism. Mitosis:  Mitosis appears to be rare. Nuclear_Crowding:  The nuclei are crowded to a moderate degree. Conclusion:  Lg / punlmp.']\n",
      "-----------------\n",
      " Polarity:  Polarity is negligibly lost. Nucleoli:  The nucleoli of nuclei are inconspicuous. Nuclear_Feature:  The nuclei are moderately pleomorphic. Mitosis:  There are rarely mitotic figures throughout the tissue. Nuclear_Crowding:  Nuclei are moderately crowded together. Conclusion:  Lg / punlmp.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "import sys\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "#from utils.local_utils import *\n",
    "\n",
    "Data_root = os.path.join('..','..', 'Data', 'bladder_data')\n",
    "annotation_folder = os.path.join(Data_root, 'Annotation') \n",
    "Img_folder = os.path.join(Data_root, 'Img') \n",
    "\n",
    "output_json = os.path.join(Data_root,'total_anno.json') \n",
    "\n",
    "# anno_filelist, anno_filenames = getfilelist(annotation_folder,['.json'] )\n",
    "\n",
    "# total_num = len(anno_filelist)\n",
    "# print(total_num)\n",
    "\n",
    "# total_json = []\n",
    "# test_num = total_num\n",
    "\n",
    "# # pool for one hot label\n",
    "# n_labels = 4\n",
    "# one_hot = np.eye(n_labels).astype(np.int)\n",
    "\n",
    "\n",
    "hdf5_filepath = os.path.join(Data_root, 'images_caption.h5')\n",
    "\n",
    "\n",
    "with h5py.File(hdf5_filepath,'r') as testh5:\n",
    "    imgs = testh5['images']\n",
    "    sents = testh5['sentences']\n",
    "    labs  = testh5['conclusion']\n",
    "    fns   = testh5['filenames']\n",
    "    \n",
    "    print(imgs.shape)\n",
    "    print(sents.shape)\n",
    "    sents_list = sents.value[[1,3,1,4]]\n",
    "    this_sent = sents_list[0]\n",
    "    print(this_sent)\n",
    "    print('-----------------')\n",
    "    print(this_sent[0])\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import json\n",
    "import re\n",
    "\n",
    "def split_words(words):\n",
    "    return re.findall(r'\\w+|\\S+', words)\n",
    "\n",
    "save_root = os.path.join('..','..', 'Data', 'bladder_data')\n",
    "\n",
    "dict_path = os.path.join(save_root,'dictionary.json')\n",
    "worddict = OrderedDict()\n",
    "worddict['<eos>'] = 0\n",
    "worddict['UNK'] = 1\n",
    "wordIndex = 2\n",
    "\n",
    "Dicts = {}\n",
    "\n",
    "\n",
    "with h5py.File(hdf5_filepath,'r') as testh5:\n",
    "    imgs = testh5['images']\n",
    "    sents = testh5['sentences']\n",
    "    labs  = testh5['conclusion']\n",
    "    fns   = testh5['filenames']\n",
    "    all_sents = sents.value\n",
    "    for this_list in all_sents:\n",
    "        for this_sent in this_list:\n",
    "            this_sent = this_sent.decode()\n",
    "            words = split_words(this_sent)\n",
    "            for k in words:\n",
    "                if k not in worddict:\n",
    "                    worddict[k] = wordIndex\n",
    "                    wordIndex = wordIndex + 1\n",
    "\n",
    "word_idict = dict()\n",
    "for kk, vv in worddict.items():\n",
    "    word_idict[vv] = kk\n",
    "word_idict[0] = '<eos>'\n",
    "word_idict[1] = 'UNK'\n",
    "\n",
    "Dicts['encoder'] = worddict\n",
    "Dicts['decoder'] = word_idict\n",
    "with open(dict_path,'w') as f:\n",
    "    json.dump(Dicts, f)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1  1\n",
      " 3  1\n",
      " 3  2\n",
      " 2  2\n",
      "[torch.LongTensor of size 4x2]\n",
      "\n",
      "\n",
      " 1  0  0  0\n",
      " 0  1  0  0\n",
      " 0  0  0  1\n",
      " 0  1  0  0\n",
      " 0  0  1  0\n",
      "[torch.cuda.FloatTensor of size 5x4 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torch.autograd import Variable\n",
    "def to_variable(x, requires_grad=False, cuda=False):\n",
    "    if type(x) is Variable:\n",
    "        return x\n",
    "    if type(x) is np.ndarray:\n",
    "        x = torch.from_numpy(x)\n",
    "    if cuda:\n",
    "       return Variable(x, requires_grad=requires_grad).cuda()\n",
    "    else:\n",
    "       return Variable(x, requires_grad=requires_grad) \n",
    "\n",
    "def to_device(src, ref=None, var = True):\n",
    "    \n",
    "    src = to_variable(src) if var else src\n",
    "    return src.cuda(ref.get_device()) if (ref is not None and ref.is_cuda) else src\n",
    "\n",
    "def one_hot(nwords, ref=None):\n",
    "    eye_tensor = to_device(torch.eye(nwords),ref, var=False)\n",
    "    def f(tensor_int):\n",
    "        if type(tensor_int) is int:\n",
    "            tensor_int  = [tensor_int]\n",
    "        if type(tensor_int) is list :\n",
    "            tensor_int = torch.LongTensor(tensor_int)\n",
    "        tensor_int = to_device(tensor_int, ref, var=False)\n",
    "        size = list(tensor_int.size()) \n",
    "        flat = tensor_int.view(-1)\n",
    "        flat_emb = torch.index_select(eye_tensor, 0, flat)\n",
    "        new_shape = size + [nwords]\n",
    "        emb = flat_emb.view(*new_shape)\n",
    "        return Variable(emb)\n",
    "    return f\n",
    "\n",
    "Input = torch.Tensor([ [1,1],[3,1],[3,2],[2,2]]).long()\n",
    "ref = Input.cuda()\n",
    "print(Input)\n",
    "\n",
    "emb = one_hot(4, ref)\n",
    "res = emb([0,1,3,1,2])\n",
    "print(res.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "np.mod(batch_count, args.validfreq) == 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print coco.keys()\n",
    "print type(coco['images'])\n",
    "print type(coco['dataset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'sentids': [770337, 771687, 772707, 776154, 781998], u'filepath': u'val2014', u'filename': u'COCO_val2014_000000391895.jpg', u'imgid': 0, u'split': u'test', u'sentences': [{u'tokens': [u'a', u'man', u'with', u'a', u'red', u'helmet', u'on', u'a', u'small', u'moped', u'on', u'a', u'dirt', u'road'], u'raw': u'A man with a red helmet on a small moped on a dirt road. ', u'imgid': 0, u'sentid': 770337}, {u'tokens': [u'man', u'riding', u'a', u'motor', u'bike', u'on', u'a', u'dirt', u'road', u'on', u'the', u'countryside'], u'raw': u'Man riding a motor bike on a dirt road on the countryside.', u'imgid': 0, u'sentid': 771687}, {u'tokens': [u'a', u'man', u'riding', u'on', u'the', u'back', u'of', u'a', u'motorcycle'], u'raw': u'A man riding on the back of a motorcycle.', u'imgid': 0, u'sentid': 772707}, {u'tokens': [u'a', u'dirt', u'path', u'with', u'a', u'young', u'person', u'on', u'a', u'motor', u'bike', u'rests', u'to', u'the', u'foreground', u'of', u'a', u'verdant', u'area', u'with', u'a', u'bridge', u'and', u'a', u'background', u'of', u'cloud', u'wreathed', u'mountains'], u'raw': u'A dirt path with a young person on a motor bike rests to the foreground of a verdant area with a bridge and a background of cloud-wreathed mountains. ', u'imgid': 0, u'sentid': 776154}, {u'tokens': [u'a', u'man', u'in', u'a', u'red', u'shirt', u'and', u'a', u'red', u'hat', u'is', u'on', u'a', u'motorcycle', u'on', u'a', u'hill', u'side'], u'raw': u'A man in a red shirt and a red hat is on a motorcycle on a hill side.', u'imgid': 0, u'sentid': 781998}], u'cocoid': 391895}\n",
      "---------------\n",
      "coco\n",
      "---------------\n",
      "[u'sentids', u'filepath', u'filename', u'imgid', u'split', u'sentences', u'cocoid']\n",
      "---------------\n",
      "[{u'tokens': [u'a', u'man', u'with', u'a', u'red', u'helmet', u'on', u'a', u'small', u'moped', u'on', u'a', u'dirt', u'road'], u'raw': u'A man with a red helmet on a small moped on a dirt road. ', u'imgid': 0, u'sentid': 770337}, {u'tokens': [u'man', u'riding', u'a', u'motor', u'bike', u'on', u'a', u'dirt', u'road', u'on', u'the', u'countryside'], u'raw': u'Man riding a motor bike on a dirt road on the countryside.', u'imgid': 0, u'sentid': 771687}, {u'tokens': [u'a', u'man', u'riding', u'on', u'the', u'back', u'of', u'a', u'motorcycle'], u'raw': u'A man riding on the back of a motorcycle.', u'imgid': 0, u'sentid': 772707}, {u'tokens': [u'a', u'dirt', u'path', u'with', u'a', u'young', u'person', u'on', u'a', u'motor', u'bike', u'rests', u'to', u'the', u'foreground', u'of', u'a', u'verdant', u'area', u'with', u'a', u'bridge', u'and', u'a', u'background', u'of', u'cloud', u'wreathed', u'mountains'], u'raw': u'A dirt path with a young person on a motor bike rests to the foreground of a verdant area with a bridge and a background of cloud-wreathed mountains. ', u'imgid': 0, u'sentid': 776154}, {u'tokens': [u'a', u'man', u'in', u'a', u'red', u'shirt', u'and', u'a', u'red', u'hat', u'is', u'on', u'a', u'motorcycle', u'on', u'a', u'hill', u'side'], u'raw': u'A man in a red shirt and a red hat is on a motorcycle on a hill side.', u'imgid': 0, u'sentid': 781998}]\n",
      "---------------\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "print coco['images'][0]\n",
    "print('---------------')\n",
    "print coco['dataset']\n",
    "print('---------------')\n",
    "print(coco['images'][0].keys())\n",
    "print('---------------')\n",
    "print coco['images'][0]['sentences']\n",
    "print('---------------')\n",
    "print coco['images'][0]['split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bladder = json.load(open('../../Data/bladder/caption_datasets/dataset_coco.json', 'r'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
