{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lets download the annotations from http://mscoco.org/dataset/#download\n",
    "import os\n",
    "import json\n",
    "coco = json.load(open('../../Data/neural_talk_data/caption_datasets/dataset_coco.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'h5File' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-1eedfb7a4c08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mh5py_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sentences\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstring_dt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mh5File\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mh5File\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'xxx.h5'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'h5File' is not defined"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "def create_dataset(h5py_file, string_list):\n",
    "    data = np.array([['I', 'am', 'a', 'sentence'], ['another', 'sentence']], dtype=object)\n",
    "    string_dt = h5py.special_dtype(vlen=str)\n",
    "    h5py_file.create_dataset(\"sentences\", data=data, dtype=string_dt)\n",
    "    \n",
    "h5File.close()\n",
    "h5File=h5py.File('xxx.h5','w')\n",
    "\n",
    "create_dataset(h5File)\n",
    "h5File.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.]\n",
      " [ 0.  1.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "aa =  np.eye(5)\n",
    "print aa[np.array([1,3,1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator annotation json (may be done already)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50008\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "from utils.local_utils import *\n",
    "\n",
    "Data_root = os.path.join('..','..', 'Data', 'bladder')\n",
    "save_root = os.path.join('..','..', 'Data', 'bladder_data')\n",
    "\n",
    "annotation_folder = os.path.join(Data_root, 'Annotation') \n",
    "Img_folder = os.path.join(Data_root, 'Img') \n",
    "\n",
    "output_json = os.path.join(save_root,'total_anno.json') \n",
    "\n",
    "anno_filelist, anno_filenames = getfilelist(annotation_folder,['.json'] )\n",
    "\n",
    "total_num = len(anno_filelist)\n",
    "print total_num\n",
    "\n",
    "total_json = []\n",
    "test_num = total_num\n",
    "\n",
    "# pool for one hot label\n",
    "n_labels = 4\n",
    "one_hot = np.eye(n_labels).astype(np.int)\n",
    "\n",
    "\n",
    "hdf5_filepath = os.path.join(save_root, 'images_caption.h5')\n",
    "hdf5_ref_filepath = os.path.join(save_root, 'images_caption_ref.json')\n",
    "\n",
    "def get_cnn_img(thisimg, shape, norm=False):\n",
    "    ''' \n",
    "    Parameters:\n",
    "    -----------\n",
    "    shape, (row, col, channel).\n",
    "    norm: if you preder to normalize iter\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    img: Tensor of shape(channel, row, col)\n",
    "\n",
    "    '''\n",
    "    if isinstance(thisimg, np.ndarray):\n",
    "        img = thisimg\n",
    "    elif type(thisimg) is str:\n",
    "        img = imread(thisimg)\n",
    "    img  = pre_process_img(img, yuv = False, norm= norm)  #(img, yuv = False,norm= local_norm)\n",
    "\n",
    "    img =  imresize_shape(img,shape)\n",
    "    # transpose the img to order (channel, row, col)\n",
    "    img = np.transpose(img, (2,0,1))\n",
    "    return img\n",
    "\n",
    "def parse_anno(anno_dict_list):\n",
    "\n",
    "    str_list = []\n",
    "    if type(anno_dict_list) is not list:\n",
    "        anno_dict_list = [anno_dict_list]\n",
    "    for anno_dict in anno_dict_list:         \n",
    "        thisstr = ''\n",
    "        for k, v in anno_dict.iteritems():\n",
    "            thisstr = thisstr + ' '+ k.title() +': '\n",
    "            thisstr  = thisstr + ' ' + v[1]\n",
    "        str_list.append(thisstr)\n",
    "    return str_list\n",
    "\n",
    "\n",
    "with h5py.File(hdf5_filepath,'w') as ImgHdf5:\n",
    "    #dset_img = ImgHdf5.create_dataset(\"images\", (total_num, 3, 224, 224), dtype='uint8')\n",
    "    dset_img = ImgHdf5.create_dataset(\"images\", (test_num, 3, 224, 224), dtype='uint8')\n",
    "\n",
    "    dset_conclusion = ImgHdf5.create_dataset(\"conclusion\", (test_num, n_labels), dtype='int')\n",
    "\n",
    "    string_dt = h5py.special_dtype(vlen=str)\n",
    "\n",
    "    sentence_list  = []\n",
    "    filename_list = []\n",
    "    filename_dict = {}\n",
    "\n",
    "    for idx, (fp, fn) in enumerate(zip(anno_filelist, anno_filenames )): \n",
    "        if idx == test_num:\n",
    "            break\n",
    "\n",
    "        img_name = fn + '.png'\n",
    "        thisimg = imread(os.path.join(Img_folder, img_name))\n",
    "        filename_dict[fn] = idx\n",
    "\n",
    "        new_img  = get_cnn_img(thisimg, (224, 224,3), norm=False).astype(np.uint8)\n",
    "\n",
    "        with open(fp) as data_file:    \n",
    "            thisjson = json.load(data_file)\n",
    "        sentence_list.append(parse_anno(thisjson)) \n",
    "        filename_list.append(fn)\n",
    "\n",
    "        this_conclusion = thisjson[0]['conclusion'][0] #not beautiful\n",
    "        dset_img[idx] = new_img\n",
    "        dset_conclusion[idx] = one_hot[this_conclusion]\n",
    "\n",
    "\n",
    "    sentence_data = np.array(sentence_list, dtype=object)\n",
    "    ImgHdf5.create_dataset(\"sentences\", data=sentence_data, dtype=string_dt)\n",
    "\n",
    "    filename_data = np.array(filename_list, dtype= object)\n",
    "    ImgHdf5.create_dataset(\"filenames\", data=filename_data, dtype=string_dt)\n",
    "    ImgHdf5.close()\n",
    "\n",
    "    with open(hdf5_ref_filepath,'w') as f:\n",
    "        json.dump(filename_dict, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and test the hdf5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50008\n",
      "(50008, 3, 224, 224)\n",
      "(50008, 5)\n",
      "[[ ' Polarity:  Polarity is negligibly lost. Nucleoli:  The nucleoli of nuclei are inconspicuous. Nuclear_Feature:  The nuclei are moderately pleomorphic. Mitosis:  There are rarely mitotic figures throughout the tissue. Nuclear_Crowding:  Nuclei are moderately crowded together. Conclusion:  Lg / punlmp.'\n",
      "  ' Polarity:  Basement membrane polarity is negligibly lost. Nucleoli:  The nucleoli of nuclei are inconspicuous. Nuclear_Feature:  Moderate pleomorphism of the nuclei can be seen. Mitosis:  Mitosis is rare. Nuclear_Crowding:  Moderate nuclear crowding is present. Conclusion:  Lg / punlmp.'\n",
      "  ' Polarity:  Polarity of nuclei is negligibly lost. Nucleoli:  The nucleoli are mostly inconspicuous. Nuclear_Feature:  Moderate pleomorphism is present in the nuclei. Mitosis:  Mitotic figures are rare. Nuclear_Crowding:  The nuclei are moderately crowded. Conclusion:  Lg / punlmp.'\n",
      "  ' Polarity:  Polarity is negligibly lost. Nucleoli:  The nuclei have inconspicuous nucleoli. Nuclear_Feature:  Moderate pleomorphism of the nuclei can be seen. Mitosis:  There are rarely mitotic figures throughout the tissue. Nuclear_Crowding:  The nuclei are crowded to a moderate degree. Conclusion:  Lg / punlmp.'\n",
      "  ' Polarity:  Basement membrane polarity is negligibly lost. Nucleoli:  The nuclei have inconspicuous nucleoli. Nuclear_Feature:  The nuclei exhibit moderate pleomorphism. Mitosis:  Mitosis appears to be rare. Nuclear_Crowding:  The nuclei are crowded to a moderate degree. Conclusion:  Lg / punlmp.']\n",
      " [ ' Polarity:  Polarity along the basement membrane is negligibly lost. Nucleoli:  The nuclei have inconspicuous nucleoli. Nuclear_Feature:  There is mild pleomorphism in the nuclei. Mitosis:  Mitosis is rare. Nuclear_Crowding:  There is a mild degree of crowding. Conclusion:  Normal.'\n",
      "  ' Polarity:  Polarity of nuclei is negligibly lost. Nucleoli:  The nucleoli of nuclei are inconspicuous. Nuclear_Feature:  The nuclei are pleomorphic to a mild degree. Mitosis:  Mitosis is rare. Nuclear_Crowding:  There is a mild degree of crowding. Conclusion:  Normal.'\n",
      "  ' Polarity:  Polarity is negligibly lost. Nucleoli:  The nucleoli of nuclei are inconspicuous. Nuclear_Feature:  The nuclei are mildly pleomorphic. Mitosis:  Mitosis is rare. Nuclear_Crowding:  The nuclei are mildly crowded. Conclusion:  Normal.'\n",
      "  ' Polarity:  Basement membrane polarity is negligibly lost. Nucleoli:  The nuclei have inconspicuous nucleoli. Nuclear_Feature:  There is mild pleomorphism in the nuclei. Mitosis:  Mitosis is rare throughout the tissue. Nuclear_Crowding:  Mild crowding of the nuclei can be seen. Conclusion:  Normal.'\n",
      "  ' Polarity:  Polarity of nuclei is negligibly lost. Nucleoli:  The nuclei have inconspicuous nucleoli. Nuclear_Feature:  Pictured nuclei are mildly pleomorphic. Mitosis:  Mitosis is rare throughout the tissue. Nuclear_Crowding:  There is a mild degree of crowding. Conclusion:  Normal.']\n",
      " [ ' Polarity:  Polarity is negligibly lost. Nucleoli:  The nucleoli of nuclei are inconspicuous. Nuclear_Feature:  The nuclei are moderately pleomorphic. Mitosis:  There are rarely mitotic figures throughout the tissue. Nuclear_Crowding:  Nuclei are moderately crowded together. Conclusion:  Lg / punlmp.'\n",
      "  ' Polarity:  Basement membrane polarity is negligibly lost. Nucleoli:  The nucleoli of nuclei are inconspicuous. Nuclear_Feature:  Moderate pleomorphism of the nuclei can be seen. Mitosis:  Mitosis is rare. Nuclear_Crowding:  Moderate nuclear crowding is present. Conclusion:  Lg / punlmp.'\n",
      "  ' Polarity:  Polarity of nuclei is negligibly lost. Nucleoli:  The nucleoli are mostly inconspicuous. Nuclear_Feature:  Moderate pleomorphism is present in the nuclei. Mitosis:  Mitotic figures are rare. Nuclear_Crowding:  The nuclei are moderately crowded. Conclusion:  Lg / punlmp.'\n",
      "  ' Polarity:  Polarity is negligibly lost. Nucleoli:  The nuclei have inconspicuous nucleoli. Nuclear_Feature:  Moderate pleomorphism of the nuclei can be seen. Mitosis:  There are rarely mitotic figures throughout the tissue. Nuclear_Crowding:  The nuclei are crowded to a moderate degree. Conclusion:  Lg / punlmp.'\n",
      "  ' Polarity:  Basement membrane polarity is negligibly lost. Nucleoli:  The nuclei have inconspicuous nucleoli. Nuclear_Feature:  The nuclei exhibit moderate pleomorphism. Mitosis:  Mitosis appears to be rare. Nuclear_Crowding:  The nuclei are crowded to a moderate degree. Conclusion:  Lg / punlmp.']\n",
      " [ ' Polarity:  Polarity is negligibly lost. Nucleoli:  The nucleoli of nuclei are inconspicuous. Nuclear_Feature:  Moderate pleomorphism is present in the nuclei. Mitosis:  Mitosis is rare throughout the tissue. Nuclear_Crowding:  There is moderate crowding. Conclusion:  Lg / punlmp.'\n",
      "  ' Polarity:  Polarity along the basement membrane is negligibly lost. Nucleoli:  The nucleoli of nuclei are inconspicuous. Nuclear_Feature:  Pictured nuclei are moderately pleomorphic. Mitosis:  Mitosis is rare. Nuclear_Crowding:  There is moderate crowding. Conclusion:  Lg / punlmp.'\n",
      "  ' Polarity:  Polarity is negligibly lost. Nucleoli:  The nuclei have inconspicuous nucleoli. Nuclear_Feature:  Moderate pleomorphism is present in the nuclei. Mitosis:  Mitosis appears to be rare. Nuclear_Crowding:  There is a moderate degree of crowding. Conclusion:  Lg / punlmp.'\n",
      "  ' Polarity:  Polarity of nuclei is negligibly lost. Nucleoli:  The nucleoli are mostly inconspicuous. Nuclear_Feature:  Pictured nuclei are moderately pleomorphic. Mitosis:  Mitosis appears to be rare. Nuclear_Crowding:  There is a moderate degree of crowding. Conclusion:  Lg / punlmp.'\n",
      "  ' Polarity:  Polarity is negligibly lost. Nucleoli:  The nucleoli are mostly inconspicuous. Nuclear_Feature:  Moderate pleomorphism of the nuclei can be seen. Mitosis:  Mitosis is rare throughout the tissue. Nuclear_Crowding:  Moderate crowding of the nuclei can be seen. Conclusion:  Lg / punlmp.']]\n",
      "[[0 1 0 0]\n",
      " [1 0 0 0]\n",
      " [0 1 0 0]\n",
      " [0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "import sys\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "from utils.local_utils import *\n",
    "\n",
    "Data_root = os.path.join('..','..', 'Data', 'bladder')\n",
    "annotation_folder = os.path.join(Data_root, 'Annotation') \n",
    "Img_folder = os.path.join(Data_root, 'Img') \n",
    "\n",
    "output_json = os.path.join(Data_root,'total_anno.json') \n",
    "\n",
    "anno_filelist, anno_filenames = getfilelist(annotation_folder,['.json'] )\n",
    "\n",
    "total_num = len(anno_filelist)\n",
    "print total_num\n",
    "\n",
    "total_json = []\n",
    "test_num = total_num\n",
    "\n",
    "# pool for one hot label\n",
    "n_labels = 4\n",
    "one_hot = np.eye(n_labels).astype(np.int)\n",
    "\n",
    "\n",
    "hdf5_filepath = os.path.join(Data_root, 'images_caption.h5')\n",
    "\n",
    "\n",
    "with h5py.File(hdf5_filepath,'r') as testh5:\n",
    "    imgs = testh5['images']\n",
    "    sents = testh5['sentences']\n",
    "    labs  = testh5['conclusion']\n",
    "    fns   = testh5['filenames']\n",
    "\n",
    "    print imgs.shape\n",
    "    print sents.shape\n",
    "    print sents.value[[1,3,1,4]]\n",
    "    print labs.value[[1,3,1,4]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print coco.keys()\n",
    "print type(coco['images'])\n",
    "print type(coco['dataset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'sentids': [770337, 771687, 772707, 776154, 781998], u'filepath': u'val2014', u'filename': u'COCO_val2014_000000391895.jpg', u'imgid': 0, u'split': u'test', u'sentences': [{u'tokens': [u'a', u'man', u'with', u'a', u'red', u'helmet', u'on', u'a', u'small', u'moped', u'on', u'a', u'dirt', u'road'], u'raw': u'A man with a red helmet on a small moped on a dirt road. ', u'imgid': 0, u'sentid': 770337}, {u'tokens': [u'man', u'riding', u'a', u'motor', u'bike', u'on', u'a', u'dirt', u'road', u'on', u'the', u'countryside'], u'raw': u'Man riding a motor bike on a dirt road on the countryside.', u'imgid': 0, u'sentid': 771687}, {u'tokens': [u'a', u'man', u'riding', u'on', u'the', u'back', u'of', u'a', u'motorcycle'], u'raw': u'A man riding on the back of a motorcycle.', u'imgid': 0, u'sentid': 772707}, {u'tokens': [u'a', u'dirt', u'path', u'with', u'a', u'young', u'person', u'on', u'a', u'motor', u'bike', u'rests', u'to', u'the', u'foreground', u'of', u'a', u'verdant', u'area', u'with', u'a', u'bridge', u'and', u'a', u'background', u'of', u'cloud', u'wreathed', u'mountains'], u'raw': u'A dirt path with a young person on a motor bike rests to the foreground of a verdant area with a bridge and a background of cloud-wreathed mountains. ', u'imgid': 0, u'sentid': 776154}, {u'tokens': [u'a', u'man', u'in', u'a', u'red', u'shirt', u'and', u'a', u'red', u'hat', u'is', u'on', u'a', u'motorcycle', u'on', u'a', u'hill', u'side'], u'raw': u'A man in a red shirt and a red hat is on a motorcycle on a hill side.', u'imgid': 0, u'sentid': 781998}], u'cocoid': 391895}\n",
      "---------------\n",
      "coco\n",
      "---------------\n",
      "[u'sentids', u'filepath', u'filename', u'imgid', u'split', u'sentences', u'cocoid']\n",
      "---------------\n",
      "[{u'tokens': [u'a', u'man', u'with', u'a', u'red', u'helmet', u'on', u'a', u'small', u'moped', u'on', u'a', u'dirt', u'road'], u'raw': u'A man with a red helmet on a small moped on a dirt road. ', u'imgid': 0, u'sentid': 770337}, {u'tokens': [u'man', u'riding', u'a', u'motor', u'bike', u'on', u'a', u'dirt', u'road', u'on', u'the', u'countryside'], u'raw': u'Man riding a motor bike on a dirt road on the countryside.', u'imgid': 0, u'sentid': 771687}, {u'tokens': [u'a', u'man', u'riding', u'on', u'the', u'back', u'of', u'a', u'motorcycle'], u'raw': u'A man riding on the back of a motorcycle.', u'imgid': 0, u'sentid': 772707}, {u'tokens': [u'a', u'dirt', u'path', u'with', u'a', u'young', u'person', u'on', u'a', u'motor', u'bike', u'rests', u'to', u'the', u'foreground', u'of', u'a', u'verdant', u'area', u'with', u'a', u'bridge', u'and', u'a', u'background', u'of', u'cloud', u'wreathed', u'mountains'], u'raw': u'A dirt path with a young person on a motor bike rests to the foreground of a verdant area with a bridge and a background of cloud-wreathed mountains. ', u'imgid': 0, u'sentid': 776154}, {u'tokens': [u'a', u'man', u'in', u'a', u'red', u'shirt', u'and', u'a', u'red', u'hat', u'is', u'on', u'a', u'motorcycle', u'on', u'a', u'hill', u'side'], u'raw': u'A man in a red shirt and a red hat is on a motorcycle on a hill side.', u'imgid': 0, u'sentid': 781998}]\n",
      "---------------\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "print coco['images'][0]\n",
    "print('---------------')\n",
    "print coco['dataset']\n",
    "print('---------------')\n",
    "print(coco['images'][0].keys())\n",
    "print('---------------')\n",
    "print coco['images'][0]['sentences']\n",
    "print('---------------')\n",
    "print coco['images'][0]['split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bladder = json.load(open('../../Data/bladder/caption_datasets/dataset_coco.json', 'r'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
